{
  "paragraphs": [
    {
      "text": "%spark.conf\n\n# It is strongly recommended to set SPARK_HOME explictly instead of using the embedded spark of Zeppelin. As the function of embedded spark of Zeppelin is limited and can only run in local mode.\nSPARK_HOME /home/ometaxas/Programs/spark-3.0.1-bin-hadoop3.2\n\n#spark.jars /home/ometaxas/Programs/spark-3.0.1-bin-hadoop3.2/plugins/rapids-4-spark_2.12-0.2.0.jar,/home/ometaxas/Programs/spark-3.0.1-bin-hadoop3.2/plugins/cudf-0.15-cuda10-1.jar\n\n#spark.sql.warehouse.dir /home/ometaxas/Programs/zeppelin-0.9.0-preview2-bin-all/spark-warehouse\n\nspark.serializer org.apache.spark.serializer.KryoSerializer\nspark.kryoserializer.buffer.max 1000M\n# set driver memory to 4g\nspark.driver.memory 100g\nspark.driver.maxResultSize 5g \n\n#spark.rapids.sql.concurrentGpuTasks\u003d2\n#spark.rapids.sql.enabled true\n#spark.rapids.memory.pinnedPool.size 2G \n\n#spark.plugins com.nvidia.spark.SQLPlugin \n\n#spark.locality.wait 0s \n#spark.sql.files.maxPartitionBytes 512m \n#spark.sql.shuffle.partitions 100 \n#spark.executor.resource.gpu.amount\u003d1\n\n\nSPARK_LOCAL_DIRS /home/ometaxas/Programs/spark-3.0.1-bin-hadoop3.2/tmp,/media/datadisk/Datasets/Spark\n#,/media/datadisk/Datasets/Spark \n#/media/datadisk/Datasets/Spark\n\n# set executor memrory 110g\n# spark.executor.memory  60g\n\n\n# set executor number to be 6\n# spark.executor.instances  6\n\n\n# Uncomment the following line if you want to use yarn-cluster mode (It is recommended to use yarn-cluster mode after Zeppelin 0.8, as the driver will run on the remote host of yarn cluster which can mitigate memory pressure of zeppelin server)\n# master yarn-cluster\n\n# Uncomment the following line if you want to use yarn-client mode (It is not recommended to use it after 0.8. Because it would launch the driver in the same host of zeppelin server which will increase memory pressure of zeppelin server)\n# master yarn-client\n\n# Uncomment the following line to enable HiveContext, and also put hive-site.xml under SPARK_CONF_DIR\n# zeppelin.spark.useHiveContext true",
      "user": "anonymous",
      "dateUpdated": "2020-12-05 09:36:59.779",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1605800359478_1421580216",
      "id": "paragraph_1605800359478_1421580216",
      "dateCreated": "2020-11-19 17:39:19.478",
      "dateStarted": "2020-12-05 09:36:59.785",
      "dateFinished": "2020-12-05 09:36:59.789",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nimport org.apache.commons.lang3.StringUtils\nimport java.util.Locale;\n\nval shortNormName \u003d udf[String, String]((e:String) \u003d\u003e {\n    \n    val normname \u003d org.apache.commons.lang3.StringUtils.stripAccents(e.toLowerCase(Locale.ENGLISH))\n    //.replaceAll(\"[^\\\\p{ASCII}]\", \"\")\n     .replaceAll(\"[\u003c\u003e:´,’./\\\\\u0027\\\\\\\";(){}!@#$%^\u0026+‐–*\\\\\\\\-]+\", \"\")\n    .replaceAll(\"Æ\", \"AE\")\n    .replaceAll(\"Ð\", \"D\")\n    .replaceAll(\"Ø\", \"O\")\n    .replaceAll(\"Þ\", \"TH\")\n    .replaceAll(\"ß\", \"ss\")\n    .replaceAll(\"ð\", \"d\")\n    .replaceAll(\"æ\", \"ae\")\n    .replaceAll(\"ø\", \"o\")\n    .replaceAll(\"þ\", \"th\")\n    .replaceAll(\"Œ\", \"OE\")\n    .replaceAll(\"œ\", \"oe\")\n    .replaceAll(\"ƒ\", \"f\")\n\t.trim().split(\" \")\n    \n\n val shortName \u003d  if (normname.length \u003d\u003d 1) normname(0) else normname(0).take(1) + normname(normname.length-1)\n shortName\n\n    \n})\n\nspark.udf.register(\"shortNormName\", shortNormName)\n\nval normName \u003d udf[String, String]((e:String) \u003d\u003e {\n    \n org.apache.commons.lang3.StringUtils.stripAccents(e.toLowerCase(Locale.ENGLISH))\n     .replaceAll(\"[ \u003c\u003e:´,’./\\\\\u0027\\\\\\\";(){}!@#$%^\u0026+‐–*\\\\\\\\-]+\", \"\")\n    .replaceAll(\"Æ\", \"AE\")\n    .replaceAll(\"Ð\", \"D\")\n    .replaceAll(\"Ø\", \"O\")\n    .replaceAll(\"Þ\", \"TH\")\n    .replaceAll(\"ß\", \"ss\")\n    .replaceAll(\"ð\", \"d\")\n    .replaceAll(\"æ\", \"ae\")\n    .replaceAll(\"ø\", \"o\")\n    .replaceAll(\"þ\", \"th\")\n    .replaceAll(\"Œ\", \"OE\")\n    .replaceAll(\"œ\", \"oe\")\n    .replaceAll(\"ƒ\", \"f\")\n\t.trim()\n    \n})\n\nspark.udf.register(\"normName\", normName)\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-01 11:21:25.698",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.commons.lang3.StringUtils\nimport java.util.Locale\n\u001b[1m\u001b[34mshortNormName\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.expressions.UserDefinedFunction\u001b[0m \u003d SparkUserDefinedFunction($Lambda$3767/0x00007f6a48486040@3fd5b732,StringType,List(Some(class[value[0]: string])),None,true,true)\n\u001b[1m\u001b[34mnormName\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.expressions.UserDefinedFunction\u001b[0m \u003d SparkUserDefinedFunction($Lambda$3769/0x00007f6a48484040@73a27bbe,StringType,List(Some(class[value[0]: string])),None,true,true)\n\u001b[1m\u001b[34mres4\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.expressions.UserDefinedFunction\u001b[0m \u003d SparkUserDefinedFunction($Lambda$3769/0x00007f6a48484040@73a27bbe,StringType,List(Some(class[value[0]: string])),None,true,true)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606722812184_1774544506",
      "id": "paragraph_1606722812184_1774544506",
      "dateCreated": "2020-11-30 09:53:32.184",
      "dateStarted": "2020-12-01 11:21:25.701",
      "dateFinished": "2020-12-01 11:21:25.929",
      "status": "FINISHED"
    },
    {
      "title": "Pre-process S2 data ",
      "text": "%spark\nval S2_HOME \u003d \"/media/datadisk/Datasets/SemanticScholar/06112020\"\nval S2_sample \u003d \"/media/datadisk/Datasets/SemanticScholar/sample/sample-S2-records.gz\"\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\n\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\nimport  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\n\n\n\nval logger: Logger \u003d LoggerFactory.getLogger(\"MyZeppelinLogger\");\nlogger.info(\"Test my logger\");\n\n\n//Get Semantic Scholar articles \nval S2articlesdf \u003d spark.read.json(s\"file://$S2_HOME\")\n//val S2articlesdf \u003d spark.read.json(s\"file://$S2_sample\")\n//S2articlesdf.printSchema\n//S2articlesdf.show(5) \n\nval S2subsetdf \u003d S2articlesdf\n             //.join(broadcast(doisdf), lower(S2articlesdf(\"doi\"))\u003d\u003d\u003ddoisdf(\"doi\"), \"inner\")\n             //.filter(($\"magId\" \u003d!\u003d \"\") \u0026\u0026 ($\"magId\".isNotNull))\n             .select($\"title\", $\"id\",lower(S2articlesdf(\"doi\")).as(\"doi\"), $\"magId\", $\"fieldsOfStudy\".as(\"S2fos\"), $\"pmid\".as(\"pmId\"), $\"authors\")\n             \n//S2subsetdf.show(10)\n\n//Create pub - author rows\nval S2flatdf \u003d S2subsetdf.select($\"title\", $\"id\", $\"doi\", $\"magId\", $\"pmId\", $\"S2fos\", explode($\"authors\").as(\"authorsflat\"))\n\nval S2_Pub_Authors \u003d S2flatdf.select($\"title\".as(\"S2title\"), $\"id\".as(\"S2paperId\"), lower($\"doi\").as(\"S2doi\"), $\"S2fos\", $\"magId\", $\"pmId\", $\"authorsflat.name\".as(\"S2name\"),concat_ws(\"\",$\"authorsflat.ids\").as(\"S2authorId\"),\n                                    shorNormName($\"authorsflat.name\").as(\"S2shortNormName\"),normName( $\"authorsflat.name\").as(\"S2normName\"))\n//.persist(StorageLevel.DISK_ONLY)\n//.cache()\n\n//S2_Pub_Authors.printSchema\n//S2_Pub_Authors.show(5)\n\n//println(\"S2_Author_Pub_Cnt:\" + S2_Pub_Authors.count())\nS2_Pub_Authors.write.mode(\"overwrite\").parquet(\"/media/datadisk/Datasets/MAG_S2/S2_Pub_Authors.parquet\")\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-30 09:59:31.130",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mS2_HOME\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d /media/datadisk/Datasets/SemanticScholar/06112020\n\u001b[1m\u001b[34mS2_sample\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d /media/datadisk/Datasets/SemanticScholar/sample/sample-S2-records.gz\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.apache.spark.sql.functions.concat_ws\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer\nimport java.util.Locale\nimport org.apache.spark.storage.StorageLevel\n\u001b[1m...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1605873396623_1631414645",
      "id": "paragraph_1605873396623_1631414645",
      "dateCreated": "2020-11-20 13:56:36.624",
      "dateStarted": "2020-11-27 19:59:35.379",
      "dateFinished": "2020-11-27 23:05:00.998",
      "status": "FINISHED"
    },
    {
      "title": "Pre-process MAG Data",
      "text": "%spark\n\n\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\n\n// Specify schema for your csv file\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\n//import  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\nimport java.util.Calendar;\n\n//org.apache.commons.lang3.StringUtils.stripAccents(input.toLowerCase(Locale.ENGLISH));\n\nval logger: Logger \u003d LoggerFactory.getLogger(\"MyZeppelinLogger\");\nlogger.info(\"Test my logger\");\n\n\n//Get MAG AUthor - Pub pairs\nval MAG_HOME \u003d \"/media/datadisk/Datasets/MAG/20201109/mag\"\nval MAG_ADV \u003d  \"/media/datadisk/Datasets/MAG/20201109/advanced\"\nval paperAuthorsAffTsvFilename \u003d \"PaperAuthorAffiliations.txt\"\nval authorsAffTsvFilename \u003d \"Authors.txt\"\nval papersTsvFilename \u003d \"Papers.txt\"\n\n\nval paperAuthorAffSchema \u003d new StructType().\n                add(\"paperId\", LongType, false).\n                add(\"authorId\", LongType, false).                \n                add(\"affiliationId\", LongType, true).\n                add(\"authorSequenceNumber\",IntegerType, true).\n                add(\"originalAuthor\", StringType, true).\n                add(\"originalAffiliation\", StringType, true)\n\n                \nval paperAuthorAffdf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n                schema(paperAuthorAffSchema).\n                csv(s\"file://$MAG_HOME/$paperAuthorsAffTsvFilename\")\n                \n                \nval authorSchema \u003d new StructType().\n                add(\"authorId\", LongType, false).\n                add(\"rank\", LongType, true).                \n                add(\"normalizedName\", StringType, true).\n                add(\"displayName\",StringType, true).\n                add(\"lastKnownAffiliationId\", LongType, true).\n                add(\"paperCount\", LongType, true).\n                add(\"paperFamilyCount\", LongType, true).\n                add(\"citationCount\", LongType, true).\n                add(\"createdDate\", DateType, true)\n                \n\n                \nval authordf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n                schema(authorSchema).\n                csv(s\"file://$MAG_HOME/$authorsAffTsvFilename\")\n\nval paperSchema \u003d new StructType().\n    add(\"paperId\", LongType, false).\n    add(\"magRank\", IntegerType, true).\n    add(\"doi\", StringType, true).\n    add(\"docTypetmp\", StringType, true).\n    add(\"normalizedTitle\", StringType, true).\n    add(\"title\", StringType, false).\n    add(\"bookTitle\", StringType, true).\n    add(\"pubYear\", IntegerType, true).\n    add(\"pubDate\", StringType, true).\n    add(\"onlineDate\", StringType, true).\n    add(\"publisherName\", StringType, true).\n    add(\"journalId\", StringType, true).\n    add(\"conferenceSeriesId\", LongType, true).\n    add(\"conferenceInstancesId\", LongType, true).\n    add(\"volume\", StringType, true).\n    add(\"issue\", StringType, true).\n    add(\"firstPage\", StringType, true).\n    add(\"lastPage\", StringType, true).\n    add(\"referenceCount\", LongType, true).\n    add(\"citationCount\", LongType, true).\n    add(\"estimatedCitation\", LongType, true).\n    add(\"originalVenue\", StringType, true).\n    add(\"familyId\", StringType, true).\n    add(\"createdDate\", DateType, true)\n    \nval papersdf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n              schema(paperSchema).\n             csv(s\"file://$MAG_HOME/$papersTsvFilename\")\n\nval paperAuthorsExtdf \u003d paperAuthorAffdf\n                        .join(authordf, paperAuthorAffdf(\"authorId\")\u003d\u003d\u003dauthordf(\"authorId\"), \"inner\")\n                        .select(paperAuthorAffdf(\"authorId\").as(\"MAGauthorId\"),paperAuthorAffdf(\"paperId\").as(\"MAGpaperId\"),authordf(\"normalizedName\").as(\"MAGnormName\") , $\"affiliationId\",\n                          authordf(\"displayName\") as \"MAGname\", normName(authordf(\"normalizedName\")).as(\"normName\"), shortNormName(authordf(\"normalizedName\")).as(\"shortNormName\"))\n                        .persist(StorageLevel.DISK_ONLY)\n\npaperAuthorsExtdf.show(5)\n//println(\"paperAuthorsExtdf:\"+paperAuthorsExtdf.count())\nprintln(\"paperAuthorsExtdf completed \"+ Calendar.getInstance().getTime())                        \n\nval paperAuthorGrpAffdf \u003d paperAuthorsExtdf\n                .groupBy($\"MAGpaperId\", $\"MAGauthorId\", $\"MAGname\", $\"MAGnormName\",  $\"normName\", $\"shortNormName\")\n                .agg( collect_set(paperAuthorAffdf(\"affiliationId\")).as(\"affiliationIds\"))\n                .persist(StorageLevel.DISK_ONLY)\n                \nprintln(\"paperAuthorGrpAffdf completed \"+ Calendar.getInstance().getTime())\n                \n\n\n                      \nval authorsPerPaperdf \u003d   paperAuthorsExtdf\n                          .groupBy(paperAuthorsExtdf(\"MAGpaperId\"))\n                          .agg( collect_set($\"MAGauthorId\").as(\"authorIds\"), collect_list($\"normName\").as(\"authorNormNames\"), collect_list($\"shortNormName\").as(\"authorShortNormNames\"))\n                          .persist(StorageLevel.DISK_ONLY)\n\nauthorsPerPaperdf.show(5)\n//println(\"authorsPerPaperdf:\"+authorsPerPaperdf.count())\nprintln(\"authorsPerPaperdf completed \"+ Calendar.getInstance().getTime())                        \n                        \n//authorsPerPaperdf.write.parquet(\"/media/datadisk/Datasets/MAG_S2/authorsPerPaperdf.parquet\")\n  \n  \nval fieldsOfStudyTsvFilename \u003d \"FieldsOfStudy.txt\"\nval paperFieldsOfStudyTsvFilename \u003d \"PaperFieldsOfStudy.txt\"\nval fieldOfStudyChildrenTsvFilename \u003d  \"FieldOfStudyChildren.txt\"\n\n\n\nval paperFieldsOfStudyschema \u003d new StructType().\n                add(\"paperId\", LongType, false).\n                add(\"fieldsOfStudyId\", LongType, false).\n                add(\"score\", DoubleType, true)\n                \nval paperFieldsOfStudydf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n                schema(paperFieldsOfStudyschema).\n                csv(s\"file://$MAG_ADV/$paperFieldsOfStudyTsvFilename\")\n//paperFieldsOfStudydf.printSchema\n//paperFieldsOfStudydf.show(5)\n\n//Enrich with FoS (lvl0, lvl1 and other)\n\nval fieldsOfStudyschema \u003d new StructType().\n                add(\"fieldsOfStudyId\", LongType, false).\n                add(\"magRank\", IntegerType, true).\n                add(\"normalizedName\", StringType, true).\n                add(\"name\", StringType, true).\n                add(\"mainType\", StringType, true).\n                add(\"level\", IntegerType, true).\n                add(\"paperCount\", LongType, true).\n                add(\"paperFamilyCount\", LongType, true).\n                add(\"citationCount\", LongType, true).\n                add(\"createdDate\", DateType, true)\n                \nval fieldsOfStudydf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n                schema(fieldsOfStudyschema).\n                csv(s\"file://$MAG_ADV/$fieldsOfStudyTsvFilename\")\n\nval fieldOfStudyChildrenschema \u003d new StructType().\n                add(\"fieldOfStudyId\", LongType, false).\n                add(\"childFieldOfStudyId\", LongType, false)\n                \n                \nval fieldOfStudyChildrendf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n                schema(fieldOfStudyChildrenschema).\n                csv(s\"file://$MAG_ADV/$fieldOfStudyChildrenTsvFilename\")\n\n//val fos_lvl0 \u003d fieldsOfStudydf.filter($\"level\"\u003d\u003d\u003d0).show()\n\n//val fos_lvl1 \u003d fieldsOfStudydf.filter($\"level\"\u003d\u003d\u003d1).show()\n\n\nval paper_fos \u003d paperFieldsOfStudydf.join(broadcast(fieldsOfStudydf), paperFieldsOfStudydf(\"fieldsOfStudyId\")\u003d\u003d\u003d fieldsOfStudydf(\"fieldsOfStudyId\"), \"inner\")\n                .groupBy(paperFieldsOfStudydf(\"paperId\").as(\"paper_fos_paperId\"))\n                .agg( \n                    //    sum(when($\"date\" \u003e \"2017-03\", $\"value\")).alias(\"value3\"),\n                    //sum(when($\"date\" \u003e \"2017-04\", $\"value\")).alias(\"value4\")\n                    collect_set(when($\"level\" \u003e 1, paperFieldsOfStudydf(\"fieldsOfStudyId\"))).as(\"fosids\"),\n                    collect_set(when($\"level\" \u003d\u003d\u003d  0, paperFieldsOfStudydf(\"fieldsOfStudyId\"))).as(\"fosids_lvl0\"),\n                    collect_set(when($\"level\" \u003d\u003d\u003d  1, paperFieldsOfStudydf(\"fieldsOfStudyId\"))).as(\"fosids_lvl1\")\n                    )\n                    .persist(StorageLevel.DISK_ONLY)\n\npaper_fos.show(5)\n//println(\"authorsPerPaperdf:\"+authorsPerPaperdf.count())\nprintln(\"paper_fos completed \"+ Calendar.getInstance().getTime())                        \n\nval MAG_pub_authorsdf \u003d paperAuthorGrpAffdf\n              //.join(broadcast(doisdf), lower(papersdf(\"doi\"))\u003d\u003d\u003ddoisdf(\"doi\"), \"inner\")\n              .join(papersdf, paperAuthorGrpAffdf(\"MAGpaperId\")\u003d\u003d\u003dpapersdf(\"paperId\"), \"inner\")\n              .join(paper_fos, paper_fos(\"paper_fos_paperId\")\u003d\u003d\u003d paperAuthorGrpAffdf(\"MAGpaperId\"), \"outer\")\n              .join(authorsPerPaperdf, authorsPerPaperdf(\"MAGpaperId\")\u003d\u003d\u003dpaperAuthorGrpAffdf(\"MAGpaperId\"), \"inner\")\n              .select(papersdf(\"title\").as(\"MAGtitle\"), paperAuthorGrpAffdf(\"MAGpaperId\"),lower(papersdf(\"doi\")).as(\"MAGdoi\"), paperAuthorGrpAffdf(\"MAGname\"), \n                  paperAuthorGrpAffdf(\"MAGnormName\"),  paperAuthorGrpAffdf(\"normName\"), paperAuthorGrpAffdf(\"shortNormName\"),\n                  authorsPerPaperdf(\"authorIds\"), authorsPerPaperdf(\"authorNormNames\"), authorsPerPaperdf(\"authorShortNormNames\"),\n                  paperAuthorGrpAffdf(\"MAGauthorId\"), paperAuthorGrpAffdf(\"affiliationIds\"), paper_fos(\"fosids\"), paper_fos(\"fosids_lvl0\") ,paper_fos(\"fosids_lvl1\"))\n              //.persist(StorageLevel.DISK_ONLY)\n              //.cache()\n             //.write.csv(\"relatedFoS.csv\")\n                //fieldsOfStudydf.dropDuplicates(\"mainType\").select(\"mainType\").show(200)\n\n//println(\"MAG_Author_pubCnt:\"+MAG_pub_authorsdf.count())\n\nMAG_pub_authorsdf.write.parquet(\"/media/datadisk/Datasets/MAG_S2/MAG_pub_authors.parquet\")\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-01 00:00:25.086",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-----------+----------+----------------+-------------+-----------------+---------------+-------------+\n|MAGauthorId|MAGpaperId|     MAGnormName|affiliationId|          MAGname|       normName|shortNormName|\n+-----------+----------+----------------+-------------+-----------------+---------------+-------------+\n| 2054935087|  11310495|     仁志 野々村|         null|      仁志 野々村|     仁志野々村|     仁野々村|\n| 2140446045|  11311632|ana maria soares|         null| Ana Maria Soares| anamariasoares|      asoares|\n| 2308272889|  14468755| hiroyuki sakaue|         null|  Hiroyuki Sakaue| hiroyukisakaue|      hsakaue|\n| 1944443586|  14468663|nicholas r hiser|     98555331|Nicholas R. Hiser| nicholasrhiser|       nhiser|\n|  220152633|  14469614|cecilia estrabou|         null| Cecilia Estrabou|ceciliaestrabou|    cestrabou|\n+-----------+----------+----------------+-------------+-----------------+---------------+-------------+\nonly showing top 5 rows\n\npaperAuthorsExtdf completed Tue Dec 01 00:46:56 EET 2020\npaperAuthorGrpAffdf completed Tue Dec 01 00:46:56 EET 2020\n+----------+--------------------+--------------------+--------------------+\n|MAGpaperId|           authorIds|     authorNormNames|authorShortNormNames|\n+----------+--------------------+--------------------+--------------------+\n|      8075|         [208182240]|[arturomenendezal...|       [aaleyxandre]|\n|      9458|[523391756, 22224...|[johnvstpeter, jo...|[jpeter, jpeter, ...|\n|      9715|[2346949400, 2584...|[lesliekobayashi,...|[lkobayashi, gbar...|\n|      9945|        [2166725079]|        [niamhowens]|            [nowens]|\n|     14719|         [208477187]|      [norkntnintan]|           [nnintan]|\n+----------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\nauthorsPerPaperdf completed Tue Dec 01 01:02:26 EET 2020\n+-----------------+--------------------+-----------+--------------------+\n|paper_fos_paperId|              fosids|fosids_lvl0|         fosids_lvl1|\n+-----------------+--------------------+-----------+--------------------+\n|             9458|[2777477808, 6223...|[185592680]|          [43617362]|\n|             9715|[50440223, 278086...| [71924100]|         [126322002]|\n|             9945|[73945780, 301875...|[144133560]|         [162853370]|\n|            17971|[200925200, 13636...|[127413603]|[78519656, 119599...|\n|            21342|[2780821815, 1811...|[162324750]|[106159729, 55675...|\n+-----------------+--------------------+-----------+--------------------+\nonly showing top 5 rows\n\npaper_fos completed Tue Dec 01 01:20:34 EET 2020\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.apache.spark.sql.functions.concat_ws\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer\nimport java.util.Locale\nimport org.apache.spark.storage.StorageLevel\nimport java.util.Calendar\n\u001b[1m\u001b[34mlogger\u001b[0m: \u001b[1m\u001b[32morg.slf4j.Logger\u001b[0m \u003d org.slf4j.impl.Log4jLoggerAdapter(MyZeppelinLogger)\n\u001b[1m\u001b[34mMAG_HOME\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d /media/datadisk/Datasets/MAG/20201109/mag\n\u001b[1m\u001b[34mMAG_ADV\u001b[0m: \u001b[1m\u001b[32mStri...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d3"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d4"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1605987015380_1074874489",
      "id": "paragraph_1605987015380_1074874489",
      "dateCreated": "2020-11-21 21:30:15.380",
      "dateStarted": "2020-12-01 00:00:25.090",
      "dateFinished": "2020-12-01 03:58:43.154",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nval MAG_pub_authorsdf \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/MAG_pub_authors.parquet\")\n\nMAG_pub_authorsdf.show(20)\nMAG_pub_authorsdf.printSchema()\nprintln(\"MAG_pub_authorsdf  cnt:\"+MAG_pub_authorsdf.count())\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-01 11:17:04.921",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------------------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+----------------------------+----------------------+-----------+--------------+--------------------+-----------+--------------------+\n|                             MAGtitle|MAGpaperId|              MAGdoi|             MAGname|         MAGnormName|            normName| shortNormName|           authorIds|             authorNormNames|  authorShortNormNames|MAGauthorId|affiliationIds|              fosids|fosids_lvl0|         fosids_lvl1|\n+-------------------------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+----------------------------+----------------------+-----------+--------------+--------------------+-----------+--------------------+\n|                 El residente en A...|       147|                null|       Callejas Pozo|       callejas pozo|        callejaspozo|         cpozo|        [2616864840]|              [callejaspozo]|               [cpozo]| 2616864840|            []|[2778371403, 1634...| [71924100]|[159110408, 74909...|\n|                 Pierre Bourdieu: ...|       787|10.1007/978-3-663...|      Gerhard Wayand|      gerhard wayand|       gerhardwayand|       gwayand|        [2498526366]|             [gerhardwayand]|             [gwayand]| 2498526366|            []|        [2778828898]|[138885662]|          [15708023]|\n|                 Warning: home ene...|      1424|                null|         L.B. Belkin|          l b belkin|            lbbelkin|       lbelkin|        [2528570034]|                  [lbbelkin]|             [lbelkin]| 2528570034|            []|[59633683, 277735...| [39432304]|          [91375879]|\n|                 Parents and Healt...|      2424|                null|        John Balding|        john balding|         johnbalding|      jbalding|        [2568574094]|               [johnbalding]|            [jbalding]| 2568574094|            []|[10050518, 299328...| [71924100]|[509550671, 19417...|\n|                 AN APPRAISAL OF N...|      3438|                null|         G.L. Decker|          g l decker|            gldecker|       gdecker|[2641813421, 2642...|        [wbbigge, wbwilso...|  [wbigge, wwilson,...| 2641813421|            []|[186027771, 20665...|[127413603]|         [548081761]|\n|                 AN APPRAISAL OF N...|      3438|                null|          W.B. Bigge|           w b bigge|             wbbigge|        wbigge|[2641813421, 2642...|        [wbbigge, wbwilso...|  [wbigge, wwilson,...| 2651814381|            []|[186027771, 20665...|[127413603]|         [548081761]|\n|                 AN APPRAISAL OF N...|      3438|                null|         W.B. Wilson|          w b wilson|            wbwilson|       wwilson|[2641813421, 2642...|        [wbbigge, wbwilso...|  [wbigge, wwilson,...| 2642160036|            []|[186027771, 20665...|[127413603]|         [548081761]|\n|                 Copyright and Int...|      5130| 10.2139/ssrn.276333|    R. Anthony Reese|     r anthony reese|       ranthonyreese|        rreese|        [2101414356]|             [ranthonyreese]|              [rreese]| 2101414356|   [204250578]|[101780184, 27773...|[144133560]|         [199539241]|\n|                 CIENFUEGOS MATEO,...|     15812|                null|Antonio Martínez ...|antonio martinez ...|antoniomartinezpunal|        apunal|        [2693856692]|        [antoniomartinezp...|              [apunal]| 2693856692|            []|                  []| [17744445]|                  []|\n|                 Compresibilidad d...|     17582|                null| Oscar Hueso Cuberos| oscar hueso cuberos|   oscarhuesocuberos|      ocuberos|        [2725962448]|         [oscarhuesocuberos]|            [ocuberos]| 2725962448|            []|                  []|[121332964]|          [15708023]|\n|                 La investigación ...|     20727|                null| María Piedad Rangel| maria piedad rangel|   mariapiedadrangel|       mrangel|        [2323235678]|         [mariapiedadrangel]|             [mrangel]| 2323235678|            []|         [169715780]| [17744445]|          [15708023]|\n|                 Университетские б...|     23001|                null|Кузнецова Натела ...|кузнецова натела ...|кузнецованателано...|   кнодарьевна|[2727352900, 2595...|        [кузнецованателан...|  [кнодарьевна, мал...| 2727352900|            []|                null|       null|                null|\n|                 Университетские б...|     23001|                null|Морозова Светлана...|морозова светлана...|морозовасветланаа...|малександровна|[2727352900, 2595...|        [кузнецованателан...|  [кнодарьевна, мал...| 2595621631|            []|                null|       null|                null|\n|                 Analysis and Trea...|     28455|10.1007/978-3-319...|Margarita Puentes...|margarita puentes...|margaritapuentesv...|       mvargas|        [2161994760]|        [margaritapuentes...|             [mvargas]| 2161994760|    [31512782]|[44838205, 133386...|[192562407]|          [49040817]|\n|问：熟石膏粉（以下简称石膏粉）是陶...|     33854|                null|              王同言|              王同言|              王同言|        王同言|         [935995711]|                    [王同言]|              [王同言]|  935995711|            []|                null|       null|                null|\n|                 Usulan Perbaikan ...|     37602|                null| Vincent Nataprawira| vincent nataprawira|  vincentnataprawira|  vnataprawira|         [299503946]|        [vincentnataprawira]|        [vnataprawira]|  299503946|            []|        [2776128355]|[127413603]|         [112698675]|\n|                 Reflexións dun cr...|     44300|                null|Francisco Javier ...|francisco javier ...|franciscojavierel...|     fbasterra|        [2627447017]|        [franciscojaviere...|           [fbasterra]| 2627447017|            []|                  []|[142362112]|[58640448, 52119013]|\n|        PR11. 新しい動脈硬化指標CA...|     46735|                null|             智子 碇|             智子 碇|              智子碇|          智碇|[2170820563, 2635...|[敬一木村, 智子碇, 昌明原田]|[敬木村, 智碇, 昌原田]| 2042523542|            []|                null|       null|                null|\n|        PR11. 新しい動脈硬化指標CA...|     46735|                null|           敬一 木村|           敬一 木村|            敬一木村|        敬木村|[2170820563, 2635...|[敬一木村, 智子碇, 昌明原田]|[敬木村, 智碇, 昌原田]| 2170820563|            []|                null|       null|                null|\n|        PR11. 新しい動脈硬化指標CA...|     46735|                null|           昌明 原田|           昌明 原田|            昌明原田|        昌原田|[2170820563, 2635...|[敬一木村, 智子碇, 昌明原田]|[敬木村, 智碇, 昌原田]| 2635447223|            []|                null|       null|                null|\n+-------------------------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+----------------------------+----------------------+-----------+--------------+--------------------+-----------+--------------------+\nonly showing top 20 rows\n\nroot\n |-- MAGtitle: string (nullable \u003d true)\n |-- MAGpaperId: long (nullable \u003d true)\n |-- MAGdoi: string (nullable \u003d true)\n |-- MAGname: string (nullable \u003d true)\n |-- MAGnormName: string (nullable \u003d true)\n |-- normName: string (nullable \u003d true)\n |-- shortNormName: string (nullable \u003d true)\n |-- authorIds: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- authorNormNames: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- authorShortNormNames: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- MAGauthorId: long (nullable \u003d true)\n |-- affiliationIds: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids_lvl0: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids_lvl1: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n\nMAG_pub_authorsdf  cnt:653044459\n\u001b[1m\u001b[34mMAG_pub_authorsdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [MAGtitle: string, MAGpaperId: bigint ... 13 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606720793995_1499060641",
      "id": "paragraph_1606720793995_1499060641",
      "dateCreated": "2020-11-30 09:19:53.995",
      "dateStarted": "2020-12-01 11:17:04.923",
      "dateFinished": "2020-12-01 11:17:21.151",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nval MAG_pub_authorsdf \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/MAG_pub_authors.parquet\")\n\nMAG_pub_authorsdf.show(20)\nMAG_pub_authorsdf.printSchema()\nprintln(\"MAG_pub_authorsdf  cnt:\"+MAG_pub_authorsdf.count())\n\n//661546284\n//653044459\n//661546284\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-02 12:23:01.222",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------------------+----------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-------------------------------+--------------------------------+-----------+--------------+--------------------+-----------+--------------------+\n|                 MAGtitle|MAGpaperId|              MAGdoi|             MAGname|         MAGnormName|            normName|shortNormName|           authorIds|                authorNormNames|            authorShortNormNames|MAGauthorId|affiliationIds|              fosids|fosids_lvl0|         fosids_lvl1|\n+-------------------------+----------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-------------------------------+--------------------------------+-----------+--------------+--------------------+-----------+--------------------+\n|     The significance ...|       548|                null|            Täumer L|            l taumer|             ltaumer|      ltaumer|[2700246010, 2643...|             [ltaumer, pandrik]|              [ltaumer, pandrik]| 2643747584|            []|[2992046845, 2780...| [86803240]|          [99454951]|\n|     The significance ...|       548|                null|            Andrik P|            p andrik|             pandrik|      pandrik|[2700246010, 2643...|             [ltaumer, pandrik]|              [ltaumer, pandrik]| 2700246010|            []|[2992046845, 2780...| [86803240]|          [99454951]|\n|     Design and fabric...|      3770|                null|Rickard Marcks vo...|rickard marcks vo...|rickardmarcksvonw...|  rwurtemberg|        [2730960322]|           [rickardmarcksvon...|                   [rwurtemberg]| 2730960322|            []|[6260449, 9774980...|[192562407]|[49040817, 120665...|\n|     Composted Biosoli...|      4966|                null|   Justin Lee Fisher|   justin lee fisher|     justinleefisher|      jfisher|        [2670181452]|              [justinleefisher]|                       [jfisher]| 2670181452|            []|[123157820, 29945...| [39432304]|           [6557445]|\n|     Σχεδίαση ειδικών ...|      7011|                null|Δημήτρης Νατσιόπο...|δημήτρης νατσιόπο...|δημητρηςνατσιοπουλος|δνατσιοπουλος|         [331995734]|           [δημητρηςνατσιοπο...|                 [δνατσιοπουλος]|  331995734|            []|                  []|[138885662]|          [27206212]|\n|3Da13 植物病原菌Pantoe...|     13702|                null|             宰 池田|             宰 池田|              宰池田|       宰池田|[2142681735, 2120...|[紀弘加藤, 大輝海野, 宰池田,...|[紀加藤, 大海野, 宰池田, 知諸星]| 2233474350|            []|[2908844146, 1186...| [86803240]|          [89423630]|\n|3Da13 植物病原菌Pantoe...|     13702|                null|           大輝 海野|           大輝 海野|            大輝海野|       大海野|[2142681735, 2120...|[紀弘加藤, 大輝海野, 宰池田,...|[紀加藤, 大海野, 宰池田, 知諸星]| 2166051829|            []|[2908844146, 1186...| [86803240]|          [89423630]|\n|3Da13 植物病原菌Pantoe...|     13702|                null|           知広 諸星|           知広 諸星|            知広諸星|       知諸星|[2142681735, 2120...|[紀弘加藤, 大輝海野, 宰池田,...|[紀加藤, 大海野, 宰池田, 知諸星]| 2120820156|            []|[2908844146, 1186...| [86803240]|          [89423630]|\n|3Da13 植物病原菌Pantoe...|     13702|                null|           紀弘 加藤|           紀弘 加藤|            紀弘加藤|       紀加藤|[2142681735, 2120...|[紀弘加藤, 大輝海野, 宰池田,...|[紀加藤, 大海野, 宰池田, 知諸星]| 2142681735|            []|[2908844146, 1186...| [86803240]|          [89423630]|\n|     The First Finding...|     15030|10.1023/a:1020911...|    O. G. Shevchenko|      o g shevchenko|        ogshevchenko|  oshevchenko|[2319269296, 2801...|           [ogshevchenko, ty...|            [oshevchenko, tor...| 2319269296|  [1313323035]|[115880899, 27775...|[127313418]|[18903297, 111368...|\n|     The First Finding...|     15030|10.1023/a:1020911...|       T. Yu. Orlova|         t yu orlova|           tyuorlova|      torlova|[2319269296, 2801...|           [ogshevchenko, ty...|            [oshevchenko, tor...| 2801977400|  [1313323035]|[115880899, 27775...|[127313418]|[18903297, 111368...|\n|     Insulators for Sp...|     15944|10.1016/b978-0-08...|            W.R. Ott|             w r ott|               wrott|         wott|        [2134855002]|                        [wrott]|                          [wott]| 2134855002|    [49502546]|[511840579, 13413...|[192562407]|[77595967, 159985...|\n|     El espíritu empre...|     20138|                null|Juan Andrés Gutié...|juan andres gutie...|juanandresgutierr...|     jlazpita|        [2275107372]|           [juanandresgutier...|                      [jlazpita]| 2275107372|            []|                null|       null|                null|\n|     Non-proportional ...|     21516|10.1007/978-3-642...|Hans C. van Houwe...|hans c van houwel...| hanscvanhouwelingen| hhouwelingen|[57091189, 295130...|           [paulhceilers, ha...|            [peilers, hhouwel...|   57091189|  [2800006345]|[50382708, 730009...| [33923547]|         [105795698]|\n|     Non-proportional ...|     21516|10.1007/978-3-642...|   Paul H. C. Eilers|     paul h c eilers|        paulhceilers|      peilers|[57091189, 295130...|           [paulhceilers, ha...|            [peilers, hhouwel...| 2951301646|  [2800006345]|[50382708, 730009...| [33923547]|         [105795698]|\n|     TEMPERATURE COEFF...|     34134|                null|            K. Inoue|             k inoue|              kinoue|       kinoue|[2441211773, 2572...|           [kinoue, knishimu...|            [kinoue, knishimu...| 2572582376|            []|[175113610, 18638...|[185592680]|[115704247, 17732...|\n|     TEMPERATURE COEFF...|     34134|                null|           M. Iizumi|            m iizumi|             miizumi|      miizumi|[2441211773, 2572...|           [kinoue, knishimu...|            [kinoue, knishimu...| 2700153191|            []|[175113610, 18638...|[185592680]|[115704247, 17732...|\n|     TEMPERATURE COEFF...|     34134|                null|        K. Nishimura|         k nishimura|          knishimura|   knishimura|[2441211773, 2572...|           [kinoue, knishimu...|            [kinoue, knishimu...| 2441211773|            []|[175113610, 18638...|[185592680]|[115704247, 17732...|\n|     La institución de...|     35399|                null| Rachid El Hour Amro| rachid el hour amro|    rachidelhouramro|        ramro|        [2705314303]|             [rachidelhouramro]|                         [ramro]| 2705314303|            []|[2780381690, 3020...|[142362112]|          [15708023]|\n|     Глобальная эконом...|     35891|                null|Зуфар Фаатович Ху...|зуфар фаатович ху...|зуфарфаатовичхуса...|    зхусаинов|        [2662949013]|           [зуфарфаатовичхус...|                     [зхусаинов]| 2662949013|            []|[3018123877, 5138...| [17744445]|           [3116431]|\n+-------------------------+----------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-------------------------------+--------------------------------+-----------+--------------+--------------------+-----------+--------------------+\nonly showing top 20 rows\n\nroot\n |-- MAGtitle: string (nullable \u003d true)\n |-- MAGpaperId: long (nullable \u003d true)\n |-- MAGdoi: string (nullable \u003d true)\n |-- MAGname: string (nullable \u003d true)\n |-- MAGnormName: string (nullable \u003d true)\n |-- normName: string (nullable \u003d true)\n |-- shortNormName: string (nullable \u003d true)\n |-- authorIds: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- authorNormNames: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- authorShortNormNames: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- MAGauthorId: long (nullable \u003d true)\n |-- affiliationIds: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids_lvl0: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids_lvl1: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n\nMAG_pub_authorsdf  cnt:661546284\n\u001b[1m\u001b[34mMAG_pub_authorsdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [MAGtitle: string, MAGpaperId: bigint ... 13 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606814247953_2103858075",
      "id": "paragraph_1606814247953_2103858075",
      "dateCreated": "2020-12-01 11:17:27.953",
      "dateStarted": "2020-12-02 12:21:35.952",
      "dateFinished": "2020-12-02 12:21:49.420",
      "status": "FINISHED"
    },
    {
      "title": "Read ORCiD JSON Author-Pub files \u0026 convert to parquet",
      "text": "%spark\n\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\nimport  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\n\n//org.apache.commons.lang3.StringUtils.stripAccents(input.toLowerCase(Locale.ENGLISH));\n\n\n//val jsondf \u003d spark.read.json(\"/media/datadisk/Datasets/ORCiD/9988322/ORCID_2019_summaries/outgz/0.gz\")\nval orcid_df \u003d spark.read.json(\"/home/ometaxas/Datasets/ORCiD\")\n.select(lower($\"DOI\").as(\"doi\"), concat_ws(\" \", $\"firstName\",$\"surName\").as(\"ORCfullName\"), shortNormName( concat_ws(\" \", $\"firstName\",$\"surName\")).as(\"ORCshortNormName\"), normName(concat_ws(\" \", $\"firstName\",$\"surName\")).as(\"ORCnormName\"),  $\"pmID\".as(\"pmId\"), $\"orcId\")\n.dropDuplicates()\n//.persist(StorageLevel.DISK_ONLY)\n.cache()\n\n\norcid_df.printSchema\nprintln(\"ORCiD cnt:\" + orcid_df.count())\norcid_df.show(20)\n\norcid_df.write.parquet(\"/media/datadisk/Datasets/MAG_S2/orcid.parquet\")                    \n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-07 17:01:32.274",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- doi: string (nullable \u003d true)\n |-- ORCfullName: string (nullable \u003d false)\n |-- ORCshortNormName: string (nullable \u003d true)\n |-- ORCnormName: string (nullable \u003d true)\n |-- pmId: string (nullable \u003d true)\n |-- orcId: string (nullable \u003d true)\n\nORCiD cnt:34108075\n+--------------------+-------------------+----------------+------------------+--------+-------------------+\n|                 doi|        ORCfullName|ORCshortNormName|       ORCnormName|    pmId|              orcId|\n+--------------------+-------------------+----------------+------------------+--------+-------------------+\n|10.1016/j.ijhcs.2...|Thanasis Daradoumis|     tdaradoumis|thanasisdaradoumis|        |0000-0001-9362-4469|\n|10.1007/978-1-071...|    AlessanRSS Reis|           areis|    alessanrssreis|32754820|0000-0001-8486-7469|\n|10.1007/978-1-071...|    AlessanRSS Reis|           areis|    alessanrssreis|32865745|0000-0001-8486-7469|\n|10.1007/978-1-071...|    AlessanRSS Reis|           areis|    alessanrssreis|32813241|0000-0001-8486-7469|\n|10.1080/13880209....|    AlessanRSS Reis|           areis|    alessanrssreis|31887257|0000-0001-8486-7469|\n|10.1080/17482631....|    AlessanRSS Reis|           areis|    alessanrssreis|32780653|0000-0001-8486-7469|\n|10.1080/10717544....|    AlessanRSS Reis|           areis|    alessanrssreis|32631085|0000-0001-8486-7469|\n|10.1080/22221751....|    AlessanRSS Reis|           areis|    alessanrssreis|32731802|0000-0001-8486-7469|\n|10.1080/16549716....|    AlessanRSS Reis|           areis|    alessanrssreis|32838706|0000-0001-8486-7469|\n|10.1080/17482631....|    AlessanRSS Reis|           areis|    alessanrssreis|32815779|0000-0001-8486-7469|\n|10.1097/jnr.00000...|    AlessanRSS Reis|           areis|    alessanrssreis|32555003|0000-0001-8486-7469|\n|10.1097/wco.00000...|    AlessanRSS Reis|           areis|    alessanrssreis|32833750|0000-0001-8486-7469|\n|10.1038/s41576-02...|    AlessanRSS Reis|           areis|    alessanrssreis|32770171|0000-0001-8486-7469|\n|10.1007/s00787-02...|    AlessanRSS Reis|           areis|    alessanrssreis|32889578|0000-0001-8486-7469|\n|10.1007/s42770-02...|    AlessanRSS Reis|           areis|    alessanrssreis|32895889|0000-0001-8486-7469|\n|   10.1111/ene.14514|    AlessanRSS Reis|           areis|    alessanrssreis|32909314|0000-0001-8486-7469|\n|10.1021/acssynbio...|    AlessanRSS Reis|           areis|    alessanrssreis|32966744|0000-0001-8486-7469|\n|10.1128/mbio.0183...|    AlessanRSS Reis|           areis|    alessanrssreis|32963005|0000-0001-8486-7469|\n|   10.1111/jgs.16865|    AlessanRSS Reis|           areis|    alessanrssreis|32965024|0000-0001-8486-7469|\n|   10.1111/ene.14508|    AlessanRSS Reis|           areis|    alessanrssreis|32896024|0000-0001-8486-7469|\n+--------------------+-------------------+----------------+------------------+--------+-------------------+\nonly showing top 20 rows\n\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.apache.spark.sql.functions.concat_ws\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer\nimport java.util.Locale\nimport org.apache.spark.storage.StorageLevel\n\u001b[1m\u001b[34morcid_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [doi: string, ORCfullName: string ... 4 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d6"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d7"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d8"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d9"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d10"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1605871491169_1622597750",
      "id": "paragraph_1605871491169_1622597750",
      "dateCreated": "2020-11-20 13:24:51.169",
      "dateStarted": "2020-12-01 11:22:53.517",
      "dateFinished": "2020-12-01 11:25:11.731",
      "status": "FINISHED"
    },
    {
      "title": "Join MAG - S2 pub-author records",
      "text": "%spark\n\n\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\n\n// Specify schema for your csv file\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\n//import  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\n\nval MAG_pub_authors1 \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/MAG_pub_authors.parquet\")\n//MAG_pub_authors1.printSchema()\n\n\n\n//MAG_pub_authors.repartition(500,\"\")\n//println(MAG_pub_authors.rdd.getNumPartitions)\n//println(\"Join_Mag_auth_pubCnt:\"+MAG_pub_authors.count())\n//MAG_pub_authors.write.format(\"parquet\").bucketBy(100, \"MAGpaperId\").sortBy(\"shortNormName\").saveAsTable(\"MAG_pub_authors_bucket\")\n//MAG_pub_authorsdf.write.bucketBy(100, \"MAGpaperId\").sortBy(\"shortNormName\").parquet(\"/media/datadisk/Datasets/MAG_S2/MAG_pub_authors_bucket.parquet\")                    \n\n\nval S2_Pub_Authors1 \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_Pub_Authors.parquet\").withColumn(\"magId\",col(\"magId\").cast(LongType)).withColumnRenamed(\"magId\", \"MAGpaperId\")\n//S2_Pub_Authors1.printSchema()\n//println(S2_Pub_Authors.rdd.getNumPartitions)\n//S2_Pub_Authorsdf.write.format(\"parquet\").bucketBy(100, \"magId\").sortBy(\"S2shortNormName\").saveAsTable(\"S2_pub_authors_bucket\")\n\n\n//val MAG_pub_authorsdf \u003d spark.table(\"MAG_pub_authors_bucket\")\n//println(\"Join_Mag_auth_pubCnt:\"+MAG_pub_authorsdf.count())\n\n//val S2_Pub_Authors \u003d spark.table(\"S2_pub_authors_bucket\")\n//println(\"Join_S2_auth_pubCnt:\"+MAG_pub_authorsdf.count())\n\n\nval MAG_pub_authors \u003d MAG_pub_authors1.repartition(500, MAG_pub_authors1.col(\"MAGpaperId\"))\nval S2_Pub_Authors \u003d S2_Pub_Authors1.repartition(500, S2_Pub_Authors1.col(\"MAGpaperId\"))\n\n\nval S2_MAG_df \u003d MAG_pub_authors\n                   .join(S2_Pub_Authors, S2_Pub_Authors(\"MAGpaperId\") \u003d\u003d\u003d MAG_pub_authors(\"MAGpaperId\")  \u0026\u0026 ( S2_Pub_Authors(\"S2shortNormName\")\u003d\u003d\u003dMAG_pub_authors(\"shortNormName\")  || ( levenshtein($\"normName\", $\"S2normName\")\u003e0.8  \u0026\u0026 double_metaphone($\"normName\") \u003d\u003d\u003d double_metaphone($\"S2normName\") ) ), \"left_outer\")                  \n                   //MAG_pub_authorsdf(\"MAGtitle\"), \n                   .select(MAG_pub_authors(\"MAGpaperId\"), MAG_pub_authors(\"MAGdoi\"),  MAG_pub_authors(\"MAGname\").as(\"MAGdisplayName\"), MAG_pub_authors(\"MAGnormName\").as(\"MAGname\"), MAG_pub_authors(\"normName\").as(\"MAGnormName\"), \n                            MAG_pub_authors(\"shortNormName\").as(\"MAGshortNormName\"),  MAG_pub_authors(\"MAGauthorId\"), MAG_pub_authors(\"fosids\"), MAG_pub_authors(\"fosids_lvl0\") ,MAG_pub_authors(\"fosids_lvl1\"), \n                            MAG_pub_authors(\"authorIds\"), MAG_pub_authors(\"authorNormNames\"), MAG_pub_authors(\"authorShortNormNames\"),MAG_pub_authors(\"affiliationIds\"), \n                            S2_Pub_Authors(\"S2authorId\"),S2_Pub_Authors(\"S2paperId\"), S2_Pub_Authors(\"S2doi\"), S2_Pub_Authors(\"S2name\"), S2_Pub_Authors(\"S2shortNormName\"), S2_Pub_Authors(\"S2normName\"), S2_Pub_Authors(\"S2fos\") )\n                  // .persist(StorageLevel.DISK_ONLY)\n\n//S2_MAG_df.show(10)\n//println(\"Join_S2_Mag_auth_pubCnt:\"+S2_MAG_df.count())\nS2_MAG_df.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\")\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-03 20:56:29.118",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.apache.spark.sql.functions.concat_ws\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer\nimport java.util.Locale\nimport org.apache.spark.storage.StorageLevel\n\u001b[1m\u001b[34mMAG_pub_authors1\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [MAGtitle: string, MAGpaperId: bigint ... 13 more fields]\n\u001b[1m\u001b[34mS2_Pub_Authors1\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [S2title: string, S2paperId: string ... 8 ...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1605993979140_229979962",
      "id": "paragraph_1605993979140_229979962",
      "dateCreated": "2020-11-21 23:26:19.141",
      "dateStarted": "2020-12-03 20:56:29.125",
      "dateFinished": "2020-12-04 06:09:13.291",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nimport org.apache.spark.sql.functions.countDistinct;\nval S2_MAG_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\").filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\").select($\"S2doi\")\n\nS2_MAG_df.cache()\n\nprintln(\"s2doi diffs cnt:\"+S2_MAG_df.count())\n//println(\"s2doi diffs cnt:\"+S2_MAG_df.distinct($\"S2doi\").count())\n\nS2_MAG_df.show(50)\n\nval df3 \u003d S2_MAG_df.select(countDistinct(\"S2doi\"))\ndf3.show(false)\n\nval orcid_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/orcid.parquet\")\n.cache()\n\n\norcid_df.printSchema\nprintln(\"ORCiD cnt:\" + orcid_df.count())\norcid_df.show(40)\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-04 13:30:43.001",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "s2doi diffs cnt:90997\n+--------------------+\n|               S2doi|\n+--------------------+\n|10.1007/978-3-662...|\n|10.1007/978-3-662...|\n|10.1007/978-3-662...|\n|10.1007/978-3-662...|\n|10.25267/rev_eure...|\n|10.1111/j.1439-03...|\n|10.1111/j.1439-03...|\n|10.1007/978-3-642...|\n|10.1016/0167-2584...|\n|     10.1139/p73-042|\n|     10.1139/p73-042|\n|10.1111/j.1651-22...|\n|10.1016/j.physb.2...|\n|10.1016/j.physb.2...|\n|10.1016/j.physb.2...|\n|10.1016/j.physb.2...|\n|10.1016/j.physb.2...|\n|10.1016/s0002-927...|\n|10.1016/s0002-927...|\n|10.1016/s0002-927...|\n|10.1016/s0002-927...|\n|10.1016/0167-2584...|\n|10.1016/0039-6028...|\n|10.1111/j.1939-16...|\n|  10.1007/bf01021580|\n|  10.1007/bf01021580|\n|10.2523/iptc-1147...|\n|10.1001/archderm....|\n|10.1016/0167-2584...|\n|10.1002/chin.2011...|\n|10.1002/chin.2011...|\n|10.1002/chin.2011...|\n|10.1016/j.rapm.20...|\n|10.1016/j.rapm.20...|\n|10.1016/j.rapm.20...|\n|10.1016/j.rapm.20...|\n|10.1163/156853367...|\n|10.1037/0096-3445...|\n|10.1177/107906328...|\n|10.1177/107906328...|\n|10.1177/107906328...|\n|    10.1038/321679a0|\n|10.1016/0010-4655...|\n|  10.1007/bf02892726|\n|  10.1007/bf02892726|\n|10.1080/014311600...|\n|10.1111/j.1469-87...|\n|10.1111/j.1469-87...|\n|10.1111/j.1469-87...|\n|10.1111/j.1469-87...|\n+--------------------+\nonly showing top 50 rows\n\n+---------------------+\n|count(DISTINCT S2doi)|\n+---------------------+\n|32213                |\n+---------------------+\n\nimport org.apache.spark.sql.functions.countDistinct\n\u001b[1m\u001b[34mS2_MAG_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [S2doi: string]\n\u001b[1m\u001b[34mdf3\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [count(DISTINCT S2doi): bigint]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d3"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d4"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d5"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d6"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607075633760_2013582998",
      "id": "paragraph_1607075633760_2013582998",
      "dateCreated": "2020-12-04 11:53:53.760",
      "dateStarted": "2020-12-04 13:28:35.672",
      "dateFinished": "2020-12-04 13:28:41.545",
      "status": "FINISHED"
    },
    {
      "title": "Join ORCiD Data with MAG \u0026 S2 (based on MAG_doi)",
      "text": "%spark\n\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\n\n// Specify schema for your csv file\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\n//import  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\n\n\n\n//val jsondf \u003d spark.read.json(\"/media/datadisk/Datasets/ORCiD/9988322/ORCID_2019_summaries/outgz/0.gz\")\nval orcid_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/orcid.parquet\")\n.cache()\n\n\n//orcid_df.printSchema\n//println(\"ORCiD cnt:\" + orcid_df.count())\n//orcid_df.show(40)\n\n\nval S2_MAG_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\")\n//.cache()\n\n//S2_MAG_df.groupBy($\"S2doi\").show(10)\n\n//S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n//.cache()\n\n//println(\"s2doi diffs cnt:\"+S2_MAG_df.count())\n\n\n//println(\"s2doi diffs cnt:\"+S2_MAG_Orcid_df\n//S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 ($\"magId\".isNotNull) \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n\n\nval S2_MAG_Orcid_df1 \u003d S2_MAG_df\n                   .join(broadcast(orcid_df), (S2_MAG_df(\"MAGdoi\") \u003d\u003d\u003d orcid_df(\"doi\") || S2_MAG_df(\"S2doi\") \u003d\u003d\u003d orcid_df(\"doi\") )\u0026\u0026 ( S2_MAG_df(\"S2shortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  S2_MAG_df(\"MAGshortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  levenshtein($\"MAGnormName\", $\"ORCnormName\")\u003e0.8  \u0026\u0026 double_metaphone($\"MAGnormName\") \u003d\u003d\u003d double_metaphone($\"ORCnormName\") ) \n                   , \"left_outer\")       \n                     .select(S2_MAG_df(\"MAGpaperId\"), S2_MAG_df(\"MAGdoi\"),  S2_MAG_df(\"MAGdisplayName\"), S2_MAG_df(\"MAGname\"), S2_MAG_df(\"MAGnormName\"), \n                            S2_MAG_df(\"MAGshortNormName\"),  S2_MAG_df(\"MAGauthorId\"), S2_MAG_df(\"fosids\"), S2_MAG_df(\"fosids_lvl0\") ,S2_MAG_df(\"fosids_lvl1\"), \n                            S2_MAG_df(\"authorIds\"), S2_MAG_df(\"authorNormNames\"), S2_MAG_df(\"authorShortNormNames\"),S2_MAG_df(\"affiliationIds\"), \n                            S2_MAG_df(\"S2authorId\"),S2_MAG_df(\"S2paperId\"), S2_MAG_df(\"S2doi\"), S2_MAG_df(\"S2name\"), S2_MAG_df(\"S2shortNormName\"), S2_MAG_df(\"S2normName\"), S2_MAG_df(\"S2fos\") , orcid_df(\"orcId\"))\n                            \n                   \nS2_MAG_Orcid_df1.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid.parquet\")      \n\n/*\n\nval S2_MAG_Orcid_df2 \u003d S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n                   .join(broadcast(orcid_df), S2_MAG_df(\"MAGdoi\") \u003d\u003d\u003d orcid_df(\"doi\") \u0026\u0026 ( S2_MAG_df(\"S2shortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  S2_MAG_df(\"MAGshortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\")   \n                     || (levenshtein(fulltrim($\"MAGname\"), fulltrim($\"orcfullname\"))\u003e0.8  \u0026\u0026 double_metaphone(fulltrim($\"MAGname\")) \u003d\u003d\u003d double_metaphone(fulltrim($\"orcfullname\")) ) \n                   ), \"left_outer\")       \n                     .select(S2_MAG_df(\"MAGpaperId\"), S2_MAG_df(\"MAGdoi\"),  S2_MAG_df(\"MAGdisplayName\"), S2_MAG_df(\"MAGname\"), S2_MAG_df(\"MAGnormName\"), \n                            S2_MAG_df(\"MAGshortNormName\"),  S2_MAG_df(\"MAGauthorId\"), S2_MAG_df(\"fosids\"), S2_MAG_df(\"fosids_lvl0\") ,S2_MAG_df(\"fosids_lvl1\"), \n                            S2_MAG_df(\"authorIds\"), S2_MAG_df(\"authorNormNames\"), S2_MAG_df(\"authorShortNormNames\"),S2_MAG_df(\"affiliationIds\"), \n                            S2_MAG_df(\"S2authorId\"),S2_MAG_df(\"S2paperId\"), S2_MAG_df(\"S2doi\"), S2_MAG_df(\"S2name\"), S2_MAG_df(\"S2shortNormName\"), S2_MAG_df(\"S2normName\"), S2_MAG_df(\"S2fos\") , orcid_df(\"orcId\"))\n                            \n                   //.persist(StorageLevel.DISK_ONLY)\n\n//S2_MAG_Orcid_df.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid.parquet\")      \n\nval S2_MAG_Orcid_df \u003d       S2_MAG_Orcid_df1.union(S2_MAG_Orcid_df2)\n                    .dropDuplicates()\n                    .persist(StorageLevel.DISK_ONLY)\n                    \nS2_MAG_Orcid_df.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid.parquet\")      \n//println(\"ACMsubset cnt:\"+ACMsubsetouter.count())\n//ACMsubsetouter.orderBy(\"MAGshortNormName\").show(100) \n\nprintln(\"Orcid pub cnt:\"+S2_MAG_Orcid_df\n.filter(($\"orcid\" \u003d!\u003d \"\") \u0026\u0026 ($\"orcid\".isNotNull)).count())\n\nval df2 \u003d S2_MAG_Orcid_df.select(countDistinct(\"orcid\"))\ndf2.show(false)\n\n\nval dfMagid \u003d S2_MAG_Orcid_df.select(countDistinct(\"MAGauthorId\"))\ndfMagid.show(false)\n\nval dfS2Id \u003d S2_MAG_Orcid_df.select(countDistinct(\"S2authorId\"))\ndfS2Id.show(false)\n*/\n              \n",
      "user": "anonymous",
      "dateUpdated": "2020-12-08 17:13:04.672",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- doi: string (nullable \u003d true)\n |-- ORCfullName: string (nullable \u003d true)\n |-- ORCshortNormName: string (nullable \u003d true)\n |-- ORCnormName: string (nullable \u003d true)\n |-- pmId: string (nullable \u003d true)\n |-- orcId: string (nullable \u003d true)\n\nORCiD cnt:34108075\n+--------------------+--------------------+----------------+--------------------+--------+-------------------+\n|                 doi|         ORCfullName|ORCshortNormName|         ORCnormName|    pmId|              orcId|\n+--------------------+--------------------+----------------+--------------------+--------+-------------------+\n|10.3389/fpls.2018...|Muhammad Abdul Re...|         mrashid|muhammadabdulrehm...|        |0000-0002-4941-3469|\n|10.1007/978-1-071...|     AlessanRSS Reis|           areis|      alessanrssreis|32857345|0000-0001-8486-7469|\n|10.1007/978-1-071...|     AlessanRSS Reis|           areis|      alessanrssreis|32822033|0000-0001-8486-7469|\n|10.1007/978-1-071...|     AlessanRSS Reis|           areis|      alessanrssreis|32827140|0000-0001-8486-7469|\n|10.1080/14756366....|     AlessanRSS Reis|           areis|      alessanrssreis|32441172|0000-0001-8486-7469|\n|10.1084/jem.20190354|     AlessanRSS Reis|           areis|      alessanrssreis|32860704|0000-0001-8486-7469|\n|10.1080/19336918....|     AlessanRSS Reis|           areis|      alessanrssreis|32538273|0000-0001-8486-7469|\n|10.1080/22221751....|     AlessanRSS Reis|           areis|      alessanrssreis|32228226|0000-0001-8486-7469|\n|10.1080/22221751....|     AlessanRSS Reis|           areis|      alessanrssreis|32284022|0000-0001-8486-7469|\n|10.1080/0886022x....|     AlessanRSS Reis|           areis|      alessanrssreis|31918608|0000-0001-8486-7469|\n|10.1007/s11121-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32504393|0000-0001-8486-7469|\n|10.1007/s12015-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32691369|0000-0001-8486-7469|\n|10.1007/s10461-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32385677|0000-0001-8486-7469|\n|10.1007/s10802-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32648044|0000-0001-8486-7469|\n|10.1166/jnn.2020....|     AlessanRSS Reis|           areis|      alessanrssreis|32384973|0000-0001-8486-7469|\n|10.1080/02699931....|     AlessanRSS Reis|           areis|      alessanrssreis|32883181|0000-0001-8486-7469|\n|10.1186/s12879-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32962655|0000-0001-8486-7469|\n| 10.1055/a-1237-0490|     AlessanRSS Reis|           areis|      alessanrssreis|32961566|0000-0001-8486-7469|\n|10.1001/jamacardi...|     AlessanRSS Reis|           areis|      alessanrssreis|32915194|0000-0001-8486-7469|\n|   10.1002/jmv.26539|     AlessanRSS Reis|           areis|      alessanrssreis|32966614|0000-0001-8486-7469|\n|10.1136/bmjopen-2...|     AlessanRSS Reis|           areis|      alessanrssreis|32895275|0000-0001-8486-7469|\n|10.1007/s00586-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32895774|0000-0001-8486-7469|\n|   10.1111/jdv.16929|     AlessanRSS Reis|           areis|      alessanrssreis|32924186|0000-0001-8486-7469|\n|10.1007/s00038-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32910208|0000-0001-8486-7469|\n|10.1044/2020_jslh...|     AlessanRSS Reis|           areis|      alessanrssreis|32910735|0000-0001-8486-7469|\n|10.1213/ane.00000...|     AlessanRSS Reis|           areis|      alessanrssreis|32459667|0000-0001-8486-7469|\n|10.21037/atm.2020...|     AlessanRSS Reis|           areis|      alessanrssreis|32647727|0000-0001-8486-7469|\n|10.1186/s41038-01...|     AlessanRSS Reis|           areis|      alessanrssreis|30783604|0000-0001-8486-7469|\n| 10.2147/ppa.s175957|     AlessanRSS Reis|           areis|      alessanrssreis|30573952|0000-0001-8486-7469|\n|10.1055/s-0038-16...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.1590/1413-8123...|     AlessanRSS Reis|           areis|      alessanrssreis|30281726|0000-0001-8486-7469|\n|   10.1002/oby.22035|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.1007/s12144-01...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.14295/cs.v9i3....|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|  10.1111/micc.12416|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.4012/dmj.2016-430|     AlessanRSS Reis|           areis|      alessanrssreis|29081446|0000-0001-8486-7469|\n|10.1371/journal.p...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n| 10.1155/2014/753780|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|    10.1037/a0016901|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.1111/j.1463-13...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n+--------------------+--------------------+----------------+--------------------+--------+-------------------+\nonly showing top 40 rows\n\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.apache.spark.sql.functions.concat_ws\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer\nimport java.util.Locale\nimport org.apache.spark.storage.StorageLevel\n\u001b[1m\u001b[34morcid_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [doi: string, ORCfullName: string ... 4 more fields]\n\u001b[1m\u001b[34mS2_MAG_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [MAGpaperId: bigint, MAGdoi: string ....\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d5"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d6"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d7"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d8"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d10"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606221610014_51356091",
      "id": "paragraph_1606221610014_51356091",
      "dateCreated": "2020-11-24 14:40:10.014",
      "dateStarted": "2020-12-04 15:15:43.647",
      "dateFinished": "2020-12-04 19:21:43.846",
      "status": "FINISHED"
    },
    {
      "title": "Join ORCiD Data with MAG \u0026 S2 (try to also match with S2_doi)",
      "text": "%spark\n\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\n\n// Specify schema for your csv file\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\n//import  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\n\n\n\n//val jsondf \u003d spark.read.json(\"/media/datadisk/Datasets/ORCiD/9988322/ORCID_2019_summaries/outgz/0.gz\")\nval orcid_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/orcid.parquet\")\n.cache()\n\n\norcid_df.printSchema\nprintln(\"ORCiD cnt:\" + orcid_df.count())\norcid_df.show(40)\n\n\nval S2_MAG_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\").filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\") //take into consideration the dois which are different in S2\n//.cache()\n\n//S2_MAG_df.groupBy($\"S2doi\").show(10)\n\n//S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n//.cache()\n\n//println(\"s2doi diffs cnt:\"+S2_MAG_df.count())\n\n\n//println(\"s2doi diffs cnt:\"+S2_MAG_Orcid_df\n//S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 ($\"magId\".isNotNull) \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n\n\nval S2_MAG_Orcid_df1 \u003d S2_MAG_df\n                   .join(broadcast(orcid_df), S2_MAG_df(\"S2doi\") \u003d\u003d\u003d orcid_df(\"doi\") \u0026\u0026 ( S2_MAG_df(\"S2normName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  S2_MAG_df(\"S2normName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  levenshtein($\"S2normName\", $\"ORCnormName\")\u003e0.8  \u0026\u0026 double_metaphone($\"S2normName\") \u003d\u003d\u003d double_metaphone($\"ORCnormName\") ) \n                   , \"inner\")       \n                     .select(S2_MAG_df(\"MAGpaperId\"), S2_MAG_df(\"MAGdoi\"),  S2_MAG_df(\"MAGdisplayName\"), S2_MAG_df(\"MAGname\"), S2_MAG_df(\"MAGnormName\"), \n                            S2_MAG_df(\"MAGshortNormName\"),  S2_MAG_df(\"MAGauthorId\"), S2_MAG_df(\"fosids\"), S2_MAG_df(\"fosids_lvl0\") ,S2_MAG_df(\"fosids_lvl1\"), \n                            S2_MAG_df(\"authorIds\"), S2_MAG_df(\"authorNormNames\"), S2_MAG_df(\"authorShortNormNames\"),S2_MAG_df(\"affiliationIds\"), \n                            S2_MAG_df(\"S2authorId\"),S2_MAG_df(\"S2paperId\"), S2_MAG_df(\"S2doi\"), S2_MAG_df(\"S2name\"), S2_MAG_df(\"S2shortNormName\"), S2_MAG_df(\"S2normName\"), S2_MAG_df(\"S2fos\") , orcid_df(\"orcId\"))\n                            \n                   \nS2_MAG_Orcid_df1.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid_S2doi.parquet\")      \n\n/*\n\nval S2_MAG_Orcid_df2 \u003d S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n                   .join(broadcast(orcid_df), S2_MAG_df(\"MAGdoi\") \u003d\u003d\u003d orcid_df(\"doi\") \u0026\u0026 ( S2_MAG_df(\"S2shortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  S2_MAG_df(\"MAGshortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\")   \n                     || (levenshtein(fulltrim($\"MAGname\"), fulltrim($\"orcfullname\"))\u003e0.8  \u0026\u0026 double_metaphone(fulltrim($\"MAGname\")) \u003d\u003d\u003d double_metaphone(fulltrim($\"orcfullname\")) ) \n                   ), \"left_outer\")       \n                     .select(S2_MAG_df(\"MAGpaperId\"), S2_MAG_df(\"MAGdoi\"),  S2_MAG_df(\"MAGdisplayName\"), S2_MAG_df(\"MAGname\"), S2_MAG_df(\"MAGnormName\"), \n                            S2_MAG_df(\"MAGshortNormName\"),  S2_MAG_df(\"MAGauthorId\"), S2_MAG_df(\"fosids\"), S2_MAG_df(\"fosids_lvl0\") ,S2_MAG_df(\"fosids_lvl1\"), \n                            S2_MAG_df(\"authorIds\"), S2_MAG_df(\"authorNormNames\"), S2_MAG_df(\"authorShortNormNames\"),S2_MAG_df(\"affiliationIds\"), \n                            S2_MAG_df(\"S2authorId\"),S2_MAG_df(\"S2paperId\"), S2_MAG_df(\"S2doi\"), S2_MAG_df(\"S2name\"), S2_MAG_df(\"S2shortNormName\"), S2_MAG_df(\"S2normName\"), S2_MAG_df(\"S2fos\") , orcid_df(\"orcId\"))\n                            \n                   //.persist(StorageLevel.DISK_ONLY)\n\n//S2_MAG_Orcid_df.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid.parquet\")      \n\nval S2_MAG_Orcid_df \u003d       S2_MAG_Orcid_df1.union(S2_MAG_Orcid_df2)\n                    .dropDuplicates()\n                    .persist(StorageLevel.DISK_ONLY)\n                    \nS2_MAG_Orcid_df.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid.parquet\")      \n//println(\"ACMsubset cnt:\"+ACMsubsetouter.count())\n//ACMsubsetouter.orderBy(\"MAGshortNormName\").show(100) \n\nprintln(\"Orcid pub cnt:\"+S2_MAG_Orcid_df\n.filter(($\"orcid\" \u003d!\u003d \"\") \u0026\u0026 ($\"orcid\".isNotNull)).count())\n\nval df2 \u003d S2_MAG_Orcid_df.select(countDistinct(\"orcid\"))\ndf2.show(false)\n\n\nval dfMagid \u003d S2_MAG_Orcid_df.select(countDistinct(\"MAGauthorId\"))\ndfMagid.show(false)\n\nval dfS2Id \u003d S2_MAG_Orcid_df.select(countDistinct(\"S2authorId\"))\ndfS2Id.show(false)\n*/\n              \n",
      "user": "anonymous",
      "dateUpdated": "2020-12-08 17:14:08.440",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- doi: string (nullable \u003d true)\n |-- ORCfullName: string (nullable \u003d true)\n |-- ORCshortNormName: string (nullable \u003d true)\n |-- ORCnormName: string (nullable \u003d true)\n |-- pmId: string (nullable \u003d true)\n |-- orcId: string (nullable \u003d true)\n\nORCiD cnt:34108075\n+--------------------+--------------------+----------------+--------------------+--------+-------------------+\n|                 doi|         ORCfullName|ORCshortNormName|         ORCnormName|    pmId|              orcId|\n+--------------------+--------------------+----------------+--------------------+--------+-------------------+\n|10.3389/fpls.2018...|Muhammad Abdul Re...|         mrashid|muhammadabdulrehm...|        |0000-0002-4941-3469|\n|10.1007/978-1-071...|     AlessanRSS Reis|           areis|      alessanrssreis|32857345|0000-0001-8486-7469|\n|10.1007/978-1-071...|     AlessanRSS Reis|           areis|      alessanrssreis|32822033|0000-0001-8486-7469|\n|10.1007/978-1-071...|     AlessanRSS Reis|           areis|      alessanrssreis|32827140|0000-0001-8486-7469|\n|10.1080/14756366....|     AlessanRSS Reis|           areis|      alessanrssreis|32441172|0000-0001-8486-7469|\n|10.1084/jem.20190354|     AlessanRSS Reis|           areis|      alessanrssreis|32860704|0000-0001-8486-7469|\n|10.1080/19336918....|     AlessanRSS Reis|           areis|      alessanrssreis|32538273|0000-0001-8486-7469|\n|10.1080/22221751....|     AlessanRSS Reis|           areis|      alessanrssreis|32228226|0000-0001-8486-7469|\n|10.1080/22221751....|     AlessanRSS Reis|           areis|      alessanrssreis|32284022|0000-0001-8486-7469|\n|10.1080/0886022x....|     AlessanRSS Reis|           areis|      alessanrssreis|31918608|0000-0001-8486-7469|\n|10.1007/s11121-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32504393|0000-0001-8486-7469|\n|10.1007/s12015-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32691369|0000-0001-8486-7469|\n|10.1007/s10461-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32385677|0000-0001-8486-7469|\n|10.1007/s10802-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32648044|0000-0001-8486-7469|\n|10.1166/jnn.2020....|     AlessanRSS Reis|           areis|      alessanrssreis|32384973|0000-0001-8486-7469|\n|10.1080/02699931....|     AlessanRSS Reis|           areis|      alessanrssreis|32883181|0000-0001-8486-7469|\n|10.1186/s12879-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32962655|0000-0001-8486-7469|\n| 10.1055/a-1237-0490|     AlessanRSS Reis|           areis|      alessanrssreis|32961566|0000-0001-8486-7469|\n|10.1001/jamacardi...|     AlessanRSS Reis|           areis|      alessanrssreis|32915194|0000-0001-8486-7469|\n|   10.1002/jmv.26539|     AlessanRSS Reis|           areis|      alessanrssreis|32966614|0000-0001-8486-7469|\n|10.1136/bmjopen-2...|     AlessanRSS Reis|           areis|      alessanrssreis|32895275|0000-0001-8486-7469|\n|10.1007/s00586-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32895774|0000-0001-8486-7469|\n|   10.1111/jdv.16929|     AlessanRSS Reis|           areis|      alessanrssreis|32924186|0000-0001-8486-7469|\n|10.1007/s00038-02...|     AlessanRSS Reis|           areis|      alessanrssreis|32910208|0000-0001-8486-7469|\n|10.1044/2020_jslh...|     AlessanRSS Reis|           areis|      alessanrssreis|32910735|0000-0001-8486-7469|\n|10.1213/ane.00000...|     AlessanRSS Reis|           areis|      alessanrssreis|32459667|0000-0001-8486-7469|\n|10.21037/atm.2020...|     AlessanRSS Reis|           areis|      alessanrssreis|32647727|0000-0001-8486-7469|\n|10.1186/s41038-01...|     AlessanRSS Reis|           areis|      alessanrssreis|30783604|0000-0001-8486-7469|\n| 10.2147/ppa.s175957|     AlessanRSS Reis|           areis|      alessanrssreis|30573952|0000-0001-8486-7469|\n|10.1055/s-0038-16...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.1590/1413-8123...|     AlessanRSS Reis|           areis|      alessanrssreis|30281726|0000-0001-8486-7469|\n|   10.1002/oby.22035|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.1007/s12144-01...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.14295/cs.v9i3....|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|  10.1111/micc.12416|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.4012/dmj.2016-430|     AlessanRSS Reis|           areis|      alessanrssreis|29081446|0000-0001-8486-7469|\n|10.1371/journal.p...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n| 10.1155/2014/753780|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|    10.1037/a0016901|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n|10.1111/j.1463-13...|     AlessanRSS Reis|           areis|      alessanrssreis|        |0000-0001-8486-7469|\n+--------------------+--------------------+----------------+--------------------+--------+-------------------+\nonly showing top 40 rows\n\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.apache.spark.sql.functions.concat_ws\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer\nimport java.util.Locale\nimport org.apache.spark.storage.StorageLevel\n\u001b[1m\u001b[34morcid_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [doi: string, ORCfullName: string ... 4 more fields]\n\u001b[1m\u001b[34mS2_MAG_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [MAGpaperId: ...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d3"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d5"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607109007267_267285472",
      "id": "paragraph_1607109007267_267285472",
      "dateCreated": "2020-12-04 21:10:07.267",
      "dateStarted": "2020-12-04 23:46:43.799",
      "dateFinished": "2020-12-05 02:25:36.054",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n\nval S2_MAG_Orcid_S2doi \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid_S2doi.parquet\")\n.cache()\n\nS2_MAG_Orcid_S2doi.printSchema\nprintln(\"S2_MAG_Orcid_S2doi cnt:\" + S2_MAG_Orcid_S2doi.count())\nS2_MAG_Orcid_S2doi.show(40)\n\nS2_MAG_Orcid_S2doi.select(countDistinct(\"S2doi\")).show(false)\n\n\n//S2_MAG_Orcid_df1.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid_S2doi.parquet\")      ",
      "user": "anonymous",
      "dateUpdated": "2020-12-05 09:31:50.697",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- MAGpaperId: long (nullable \u003d true)\n |-- MAGdoi: string (nullable \u003d true)\n |-- MAGdisplayName: string (nullable \u003d true)\n |-- MAGname: string (nullable \u003d true)\n |-- MAGnormName: string (nullable \u003d true)\n |-- MAGshortNormName: string (nullable \u003d true)\n |-- MAGauthorId: long (nullable \u003d true)\n |-- fosids: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids_lvl0: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fosids_lvl1: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- authorIds: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- authorNormNames: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- authorShortNormNames: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- affiliationIds: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- S2authorId: string (nullable \u003d true)\n |-- S2paperId: string (nullable \u003d true)\n |-- S2doi: string (nullable \u003d true)\n |-- S2name: string (nullable \u003d true)\n |-- S2shortNormName: string (nullable \u003d true)\n |-- S2normName: string (nullable \u003d true)\n |-- S2fos: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- orcId: string (nullable \u003d true)\n\nS2_MAG_Orcid_S2doi cnt:2743\n+----------+--------------------+--------------------+-------------------+-----------------+----------------+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+-------------------+\n|MAGpaperId|              MAGdoi|      MAGdisplayName|            MAGname|      MAGnormName|MAGshortNormName|MAGauthorId|              fosids|fosids_lvl0|         fosids_lvl1|           authorIds|     authorNormNames|authorShortNormNames|      affiliationIds|S2authorId|           S2paperId|               S2doi|              S2name|   S2shortNormName|        S2normName|               S2fos|              orcId|\n+----------+--------------------+--------------------+-------------------+-----------------+----------------+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+-------------------+\n|2051399947|10.1007/978-94-01...|      Agnese Magnani|     agnese magnani|    agnesemagnani|        amagnani| 2143162775|[2780343419, 2022...|[185592680]|[42360764, 115704...|[589379136, 66313...|[mariocasolaro, r...|[mcasolaro, rbarb...|         [102064193]| 101259893|ca680d541b71e87d0...|10.1016/0267-6605...|          A  Magnani|          amagnani|          amagnani|[Materials Scienc...|0000-0002-6960-9418|\n|2140674970|10.1140/epjc/s100...|             S. Aoun|             s aoun|            saoun|           saoun| 2468516904|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|          [21491767]| 104516551|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|            S.  Aoun|             saoun|             saoun|           [Physics]|0000-0001-7655-389X|\n|2140674970|10.1140/epjc/s100...|          A. Blondel|          a blondel|         ablondel|        ablondel| 2972011011|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [114457229]|  50854436|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         A.  Belloni|          abelloni|          abelloni|           [Physics]|0000-0002-1727-656X|\n|2140674970|10.1140/epjc/s100...|          N. Benekos|          n benekos|         nbenekos|        nbenekos| 3087884766|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [157725225]|  80424423|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         N.  Benekos|          nbenekos|          nbenekos|           [Physics]|0000-0001-7831-8762|\n|2140674970|10.1140/epjc/s100...|          G. Azuelos|          g azuelos|         gazuelos|        gazuelos| 2405499369|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|[1304378839, 7093...| 102390659|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         G.  Azuelos|          gazuelos|          gazuelos|           [Physics]|0000-0003-4241-022X|\n|2140674970|10.1140/epjc/s100...|        R. Bartoldus|        r bartoldus|       rbartoldus|      rbartoldus| 3016191203|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|        [2801935854]|   2317658|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       R.  Bartoldus|        rbartoldus|        rbartoldus|           [Physics]|0000-0002-7314-0990|\n|2140674970|10.1140/epjc/s100...|        R. Bartoldus|        r bartoldus|       rbartoldus|      rbartoldus| 3016191203|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|        [2801935854]|   2317658|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       R.  Bartoldus|        rbartoldus|        rbartoldus|           [Physics]|0000-0003-1111-3783|\n|2140674970|10.1140/epjc/s100...|        R. Bartoldus|        r bartoldus|       rbartoldus|      rbartoldus| 3016191203|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|        [2801935854]|   2317658|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       R.  Bartoldus|        rbartoldus|        rbartoldus|           [Physics]|0000-0002-2994-2187|\n|2140674970|10.1140/epjc/s100...|        R. Bartoldus|        r bartoldus|       rbartoldus|      rbartoldus| 3016191203|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|        [2801935854]|   2317658|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       R.  Bartoldus|        rbartoldus|        rbartoldus|           [Physics]|0000-0002-8079-5688|\n|2140674970|10.1140/epjc/s100...|        R. Bartoldus|        r bartoldus|       rbartoldus|      rbartoldus| 3016191203|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|        [2801935854]|   2317658|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       R.  Bartoldus|        rbartoldus|        rbartoldus|           [Physics]|0000-0001-9211-7019|\n|2140674970|10.1140/epjc/s100...|      António Amorim|           a amorim|          aamorim|         aamorim| 2322941096|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [173304897]| 144391762|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|          A.  Amorim|           aamorim|           aamorim|           [Physics]|0000-0003-0638-2321|\n|2140674970|10.1140/epjc/s100...|              K. Lie|              k lie|             klie|            klie| 2149999122|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [157725225]| 144720538|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|          G.  Aielli|           gaielli|           gaielli|           [Physics]|0000-0002-0573-8114|\n|2140674970|10.1140/epjc/s100...|              K. Lie|              k lie|             klie|            klie| 2149999122|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [157725225]| 144720538|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|          G.  Aielli|           gaielli|           gaielli|           [Physics]|0000-0002-5779-5989|\n|2140674970|10.1140/epjc/s100...|           G. Artoni|           g artoni|          gartoni|         gartoni| 2093501103|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [861853513]| 103980443|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|          G.  Artoni|           gartoni|           gartoni|           [Physics]|0000-0002-3477-4499|\n|2140674970|10.1140/epjc/s100...|       L. A. Thomsen|        l a thomsen|        lathomsen|        lthomsen| 2787275239|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [124055696]| 115670646|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|        L.  Adamczyk|         ladamczyk|         ladamczyk|           [Physics]|0000-0002-5859-2075|\n|2140674970|10.1140/epjc/s100...|    A. Krasznahorkay|    a krasznahorkay|   akrasznahorkay|  akrasznahorkay| 2801330415|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|          [57206974]|   1726061|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|        A.  Christov|         achristov|         achristov|           [Physics]|0000-0001-8121-5860|\n|2140674970|10.1140/epjc/s100...|     Ricardo Gonçalo|    ricardo goncalo|   ricardogoncalo|        rgoncalo| 2971826124|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [184558857]|  72953448|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|      R.  Cardarelli|       rcardarelli|       rcardarelli|           [Physics]|0000-0001-7345-7798|\n|2140674970|10.1140/epjc/s100...|     Ricardo Gonçalo|    ricardo goncalo|   ricardogoncalo|        rgoncalo| 2971826124|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [184558857]|  72953448|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|      R.  Cardarelli|       rcardarelli|       rcardarelli|           [Physics]|0000-0001-8740-796X|\n|2140674970|10.1140/epjc/s100...|     Ricardo Gonçalo|    ricardo goncalo|   ricardogoncalo|        rgoncalo| 2971826124|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [184558857]|  72953448|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|      R.  Cardarelli|       rcardarelli|       rcardarelli|           [Physics]|0000-0002-2814-1337|\n|2140674970|10.1140/epjc/s100...|       Kerstin Perez|            k perez|           kperez|          kperez| 2972340605|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|[78577930, 122411...|   4075610|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|        G.  Borissov|         gborissov|         gborissov|           [Physics]|0000-0002-4226-9521|\n|2140674970|10.1140/epjc/s100...|       Nikolai Sinev|          n b sinev|          nbsinev|          nsinev| 3044260698|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [181233156]| 144667576|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|          N.  Besson|           nbesson|           nbesson|           [Physics]|0000-0001-9248-6252|\n|2140674970|10.1140/epjc/s100...|Natalia Panikashvili|     n panikashvili|    npanikashvili|   npanikashvili| 2088795085|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|          [27837315]|  80424423|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         N.  Benekos|          nbenekos|          nbenekos|           [Physics]|0000-0001-7831-8762|\n|2140674970|10.1140/epjc/s100...|          A. Astbury|          a astbury|         aastbury|        aastbury|  683682436|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [212119943]|  79433527|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         A.  Astbury|          aastbury|          aastbury|           [Physics]|0000-0003-3082-621X|\n|2140674970|10.1140/epjc/s100...|         M. J. Kobel|            m kobel|           mkobel|          mkobel| 2613580657|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|          [78650965]| 145428351|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|           M.  Cobal|            mcobal|            mcobal|           [Physics]|0000-0003-3309-0762|\n|2140674970|10.1140/epjc/s100...|       R. Cardarelli|       r cardarelli|      rcardarelli|     rcardarelli| 2793432265|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|                  []|  72953448|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|      R.  Cardarelli|       rcardarelli|       rcardarelli|           [Physics]|0000-0001-7345-7798|\n|2140674970|10.1140/epjc/s100...|       R. Cardarelli|       r cardarelli|      rcardarelli|     rcardarelli| 2793432265|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|                  []|  72953448|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|      R.  Cardarelli|       rcardarelli|       rcardarelli|           [Physics]|0000-0001-8740-796X|\n|2140674970|10.1140/epjc/s100...|       R. Cardarelli|       r cardarelli|      rcardarelli|     rcardarelli| 2793432265|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|                  []|  72953448|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|      R.  Cardarelli|       rcardarelli|       rcardarelli|           [Physics]|0000-0002-2814-1337|\n|2140674970|10.1140/epjc/s100...|D. Paredes Hernandez|d paredes hernandez|dparedeshernandez|      dhernandez| 2135617519|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [169645620]| 143708745|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         D.  Britton|          dbritton|          dbritton|           [Physics]|0000-0001-9998-4342|\n|2140674970|10.1140/epjc/s100...|              Z. Yan|              z yan|             zyan|            zyan| 2424855710|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|                  []| 104516551|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|            S.  Aoun|             saoun|             saoun|           [Physics]|0000-0001-7655-389X|\n|2140674970|10.1140/epjc/s100...|            M. Bindi|            m bindi|           mbindi|          mbindi| 1988383627|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|           [9360294]|   2102978|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|           M.  Bindi|            mbindi|            mbindi|           [Physics]|0000-0001-6172-545X|\n|2140674970|10.1140/epjc/s100...|       Mihai Caprini|          m caprini|         mcaprini|        mcaprini| 2147621050|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|                  []|   3343952|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         M.  Caprini|          mcaprini|          mcaprini|           [Physics]|0000-0002-6806-6730|\n|2140674970|10.1140/epjc/s100...|         G. Blanchot|         g blanchot|        gblanchot|       gblanchot| 2557546982|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|          [67311998]|1383079108|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|C.  Belanger-Cham...|cbelangerchampagne|cbelangerchampagne|           [Physics]|0000-0003-2368-2617|\n|2140674970|10.1140/epjc/s100...|      Irinel Caprini|          i caprini|         icaprini|        icaprini| 2012795701|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|                  []| 100927911|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         I.  Caprini|          icaprini|          icaprini|           [Physics]|0000-0003-3343-3200|\n|2140674970|10.1140/epjc/s100...|          P. Adragna|          p adragna|         padragna|        padragna| 2118684607|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [166337079]| 121549199|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         P.  Adragna|          padragna|          padragna|           [Physics]|0000-0002-6764-4789|\n|2140674970|10.1140/epjc/s100...|          P. Adragna|          p adragna|         padragna|        padragna| 2118684607|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [166337079]| 121549199|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|         P.  Adragna|          padragna|          padragna|           [Physics]|0000-0003-4201-7997|\n|2140674970|10.1140/epjc/s100...|          P. Adragna|          p adragna|         padragna|        padragna| 2118684607|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [166337079]| 116960776|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|    H.  Boterenbrood|     hboterenbrood|     hboterenbrood|           [Physics]|0000-0002-6764-4789|\n|2140674970|10.1140/epjc/s100...|          P. Adragna|          p adragna|         padragna|        padragna| 2118684607|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [166337079]| 116960776|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|    H.  Boterenbrood|     hboterenbrood|     hboterenbrood|           [Physics]|0000-0003-4201-7997|\n|2140674970|10.1140/epjc/s100...|         A. Angerami|         a angerami|        aangerami|       aangerami| 2131646857|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|          [78577930]| 144521063|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|        A.  Angerami|         aangerami|         aangerami|           [Physics]|0000-0002-0411-1141|\n|2140674970|10.1140/epjc/s100...|         Andrew Rose|        andrew rose|       andrewrose|           arose| 2108219070|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [162608824]| 115764698|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       A.  Andreazza|        aandreazza|        aandreazza|           [Physics]|0000-0003-2368-4559|\n|2140674970|10.1140/epjc/s100...|         Andrew Rose|        andrew rose|       andrewrose|           arose| 2108219070|[46460574, 179203...|[121332964]|[185544564, 10921...|[2139267368, 1987...|[afilipcic, echar...|[afilipcic, echar...|         [162608824]| 115764698|cd02e0ed2ea663e2f...|10.1007/jhep09(20...|       A.  Andreazza|        aandreazza|        aandreazza|           [Physics]|0000-0002-3368-3413|\n+----------+--------------------+--------------------+-------------------+-----------------+----------------+-----------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+-------------------+\nonly showing top 40 rows\n\n+---------------------+\n|count(DISTINCT S2doi)|\n+---------------------+\n|1315                 |\n+---------------------+\n\n\u001b[1m\u001b[34mS2_MAG_Orcid_S2doi\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [MAGpaperId: bigint, MAGdoi: string ... 20 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d6"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d7"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d8"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d9"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1607153353572_852553936",
      "id": "paragraph_1607153353572_852553936",
      "dateCreated": "2020-12-05 09:29:13.572",
      "dateStarted": "2020-12-05 09:31:50.700",
      "dateFinished": "2020-12-05 09:31:53.805",
      "status": "FINISHED"
    },
    {
      "title": "Test normalization functions",
      "text": "%spark\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\n\nval a \u003d 100\nprintln(a)\n\n\ndef fulltrim(e:String): String \u003d {\n    \n return org.apache.commons.lang3.StringUtils.stripAccents(e.toLowerCase(Locale.ENGLISH))\n    .replaceAll(\"[ \u003c\u003e:´,’./\\\\\u0027\\\\\\\";(){}!@#$%^\u0026+‐–*\\\\\\\\-]+\", \"\")\n    .replaceAll(\"Æ\", \"AE\")\n    .replaceAll(\"Ð\", \"D\")\n    .replaceAll(\"Ø\", \"O\")\n    .replaceAll(\"Þ\", \"TH\")\n    .replaceAll(\"ß\", \"ss\")\n    .replaceAll(\"ð\", \"d\")\n    .replaceAll(\"æ\", \"ae\")\n    .replaceAll(\"ø\", \"o\")\n    .replaceAll(\"þ\", \"th\")\n    .replaceAll(\"Œ\", \"OE\")\n    .replaceAll(\"œ\", \"oe\")\n    .replaceAll(\"ƒ\", \"f\")\n\t\t\t\t.trim()\n    \n}\n/*\nÆ → AE\nÐ → D\nØ → O\nÞ → TH\nß → ss\næ → ae\nð → d\nø → o\nþ → th\nŒ → OE\nœ → oe\nƒ → f\"\n*/\ndef unaccent2(e: String): String \u003d {\n  val normname \u003d org.apache.commons.lang3.StringUtils.stripAccents(e.toLowerCase(Locale.ENGLISH))\n    //.replaceAll(\"[^\\\\p{ASCII}]\", \"\")\n    .replaceAll(\"[\u003c\u003e:´,’./\\\\\u0027\\\\\\\";(){}!@#$%^\u0026+‐–*\\\\\\\\-]+\", \"\")\n    .replaceAll(\"Æ\", \"AE\")\n    .replaceAll(\"Ð\", \"D\")\n    .replaceAll(\"Ø\", \"O\")\n    .replaceAll(\"Þ\", \"TH\")\n    .replaceAll(\"ß\", \"ss\")\n    .replaceAll(\"ð\", \"d\")\n    .replaceAll(\"æ\", \"ae\")\n    .replaceAll(\"ø\", \"o\")\n    .replaceAll(\"þ\", \"th\")\n    .replaceAll(\"Œ\", \"OE\")\n    .replaceAll(\"œ\", \"oe\")\n    .replaceAll(\"ƒ\", \"f\")\n\t\t\t\t.trim().split(\" \")\n    \n\n val shortName \u003d  if (normname.length \u003d\u003d 1) normname(0) else normname(0).take(1) + normname(normname.length-1)\n return  shortName\n  \n}\n\ndef unaccent3(e: String): String \u003d {\n  val normname \u003d \n  //e\n  org.apache.commons.lang3.StringUtils.stripAccents(e.toLowerCase(Locale.ENGLISH))\n     //.replaceAll(\"[^\\\\p{ASCII}]\", \"\")\n    .replaceAll(\"[\u003c\u003e:´,’./\\\\\u0027\\\\\\\";(){}!@#$%^\u0026+–*\\\\\\\\-]+\", \"\")\n    .trim()\n    .split(\" \")\n\n  val shortName \u003d\n    if (normname.length \u003d\u003d 1) normname(0)\n    else normname(0).take(1) + normname(normname.length - 1)\n  return shortName\n}\n\n//println(\"chinese:\"+ unaccent2(\"福村 健\"))\n\nprintln(unaccent2(\"Søsren Løsvtrup\"))\nprintln(fulltrim(\"Søsren Løsvtrup\"))\n\nprintln(unaccent2(\"Tĥïŝ ĩš â fůňķŷ Šťŕĭńġ\"))\nprintln(fulltrim(\"Tĥïŝ ĩš â fůňķŷ Šťŕĭńġ\"))\n\n\n\nprintln(unaccent2(\"Pura López‐Colomé\"))\nprintln(fulltrim(\"Pura López‐Colomé\"))\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-01 11:27:02.276",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "100\nslosvtrup\nsosrenlosvtrup\ntstring\nthisisafunkystring\nplopezcolome\npuralopezcolome\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\n\u001b[1m\u001b[34ma\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m \u003d 100\n\u001b[1m\u001b[34mfulltrim\u001b[0m: \u001b[1m\u001b[32m(e: String)String\u001b[0m\n\u001b[1m\u001b[34munaccent2\u001b[0m: \u001b[1m\u001b[32m(e: String)String\u001b[0m\n\u001b[1m\u001b[34munaccent3\u001b[0m: \u001b[1m\u001b[32m(e: String)String\u001b[0m\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606472529243_799120251",
      "id": "paragraph_1606472529243_799120251",
      "dateCreated": "2020-11-27 12:22:09.243",
      "dateStarted": "2020-11-27 16:53:18.350",
      "dateFinished": "2020-11-27 16:53:18.525",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nimport com.github.mrpowers.spark.stringmetric.SimilarityFunctions._\nimport com.github.mrpowers.spark.stringmetric.PhoneticAlgorithms._\n\n// Specify schema for your csv file\nimport org.apache.spark.sql.types._\nimport org.apache.commons.lang.StringUtils\nimport java.lang.Integer.parseInt\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.apache.spark.sql.functions.concat_ws;\nimport org.apache.spark.sql.functions.countDistinct;\n//import  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils\nimport java.text.Normalizer;\nimport java.util.Locale;\nimport org.apache.spark.storage.StorageLevel;\nimport java.util.Calendar;\n\nprintln(Calendar.getInstance().getTime())\n\nval orcid_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/orcid.parquet\")\nprintln(\"ORCiD cnt:\" + orcid_df.count())\nprintln(Calendar.getInstance().getTime())\n\nval S2_MAG_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\")\nprintln(\"s2doi diffs cnt:\"+S2_MAG_df.count())\nprintln(Calendar.getInstance().getTime())\n\n/*\nprintln(Calendar.getInstance().getTime())\nS2_MAG_df.groupBy($\"MAGdoi\")\n.agg( collect_list($\"MAGshortNormName\") as \"magauthors\", collect_list($\"S2shortNormName\") as \"s2authors\").show(10)\n\nprintln(Calendar.getInstance().getTime())\n\nval S2_MAG_df_diffs \u003d S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n//.cache()\n\nprintln(\"s2doi diffs cnt:\"+S2_MAG_df_diffs.count())\nprintln(Calendar.getInstance().getTime())\n\n//val dfdoidiffs \u003d S2_MAG_df.select(countDistinct(\"S2doi\"))\n//dfdoidiffs.show(false)\n*/\n\nval S2_MAG_Orcid_df1 \u003d S2_MAG_df\n       //.join(broadcast(orcid_df), S2_MAG_df(\"MAGdoi\") \u003d\u003d\u003d orcid_df(\"doi\") \u0026\u0026 ( S2_MAG_df(\"S2shortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  S2_MAG_df(\"MAGshortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\")   \n                   .join(orcid_df, S2_MAG_df(\"MAGdoi\") \u003d\u003d\u003d orcid_df(\"doi\") \u0026\u0026 ( S2_MAG_df(\"S2shortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\") ||  S2_MAG_df(\"MAGshortNormName\")\u003d\u003d\u003dorcid_df(\"ORCshortNormName\")   \n                  // || (levenshtein(fulltrim($\"MAGname\"), fulltrim($\"orcfullname\"))\u003e80  \u0026\u0026 soundex(fulltrim($\"MAGname\")) \u003d\u003d\u003d soundex(fulltrim($\"orcfullname\")) ) \n                   ), \"outer\")                  \n                   .select(S2_MAG_df(\"MAGtitle\"), S2_MAG_df(\"MAGpaperId\"), S2_MAG_df(\"MAGdoi\"),  S2_MAG_df(\"MAGshortNormName\"), S2_MAG_df(\"MAGname\"), S2_MAG_df(\"MAGnormName\"), S2_MAG_df(\"MAGauthorId\")\n                     , double_metaphone(S2_MAG_df(\"MAGnormName\")).as(\"soundexFull\"), double_metaphone(S2_MAG_df(\"MAGshortNormName\")).as(\"soundexShort\")\n                     //,S2_MAG_df(\"S2fos)\n                    , S2_MAG_df(\"affiliationId\"), S2_MAG_df(\"S2authorId\"),S2_MAG_df(\"S2paperId\"), S2_MAG_df(\"S2doi\"), S2_MAG_df(\"S2name\"), S2_MAG_df(\"S2shortNormName\"), orcid_df(\"orcId\"))\n                  // .persist(StorageLevel.DISK_ONLY)\n\nprintln(\"Join with ORciD cnt:\"+S2_MAG_Orcid_df1.count())\nprintln(Calendar.getInstance().getTime())\n\nS2_MAG_Orcid_df1.write.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_Orcid.parquet\")      \nprintln(Calendar.getInstance().getTime())\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-25 23:58:59.745",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Wed Nov 25 23:58:59 EET 2020\nORCiD cnt:34108075\nWed Nov 25 23:59:03 EET 2020\ns2doi diffs cnt:714744779\nWed Nov 25 23:59:04 EET 2020\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 168 in stage 8.0 failed 1 times, most recent failure: Lost task 168.0 in stage 8.0 (TID 1442, PC192.168.2.5.station, executor driver): java.lang.OutOfMemoryError: Could not allocate native memory: std::bad_alloc: RMM failure at: /usr/local/rapids/include/rmm/mr/device/pool_memory_resource.hpp:167: Maximum pool size exceeded\n\tat ai.rapids.cudf.Rmm.allocInternal(Native Method)\n\tat ai.rapids.cudf.Rmm.alloc(Rmm.java:319)\n\tat ai.rapids.cudf.Rmm.alloc(Rmm.java:308)\n\tat ai.rapids.cudf.DeviceMemoryBuffer.allocate(DeviceMemoryBuffer.java:125)\n\tat ai.rapids.cudf.JCudfSerialization.readTableFrom(JCudfSerialization.java:1477)\n\tat ai.rapids.cudf.JCudfSerialization.readTableFrom(JCudfSerialization.java:1522)\n\tat com.nvidia.spark.rapids.GpuColumnarBatchSerializerInstance$$anon$2$$anon$3.tryReadNext(GpuColumnarBatchSerializer.scala:152)\n\tat com.nvidia.spark.rapids.GpuColumnarBatchSerializerInstance$$anon$2$$anon$3.hasNext(GpuColumnarBatchSerializer.scala:175)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat com.nvidia.spark.rapids.RemoveEmptyBatchIterator.hasNext(GpuCoalesceBatches.scala:125)\n\tat com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.next(GpuCoalesceBatches.scala:281)\n\tat com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.next(GpuCoalesceBatches.scala:148)\n\tat com.nvidia.spark.rapids.GpuColumnarBatchSorter$$anon$1.loadNextBatch(GpuSortExec.scala:141)\n\tat com.nvidia.spark.rapids.GpuColumnarBatchSorter$$anon$1.hasNext(GpuSortExec.scala:188)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.gpucolumnartorow_nextBatch_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeFullOuterJoinScanner.advancedLeft(SortMergeJoinExec.scala:1042)\n\tat org.apache.spark.sql.execution.joins.SortMergeFullOuterJoinScanner.\u003cinit\u003e(SortMergeJoinExec.scala:1032)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.$anonfun$doExecute$1(SortMergeJoinExec.scala:286)\n\tat org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n  at scala.Option.foreach(Option.scala:407)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n  at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n  at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)\n  at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:2981)\n  at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:2980)\n  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\n  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\n  at org.apache.spark.sql.Dataset.count(Dataset.scala:2980)\n  ... 44 elided\nCaused by: java.lang.OutOfMemoryError: Could not allocate native memory: std::bad_alloc: RMM failure at: /usr/local/rapids/include/rmm/mr/device/pool_memory_resource.hpp:167: Maximum pool size exceeded\n  at ai.rapids.cudf.Rmm.allocInternal(Native Method)\n  at ai.rapids.cudf.Rmm.alloc(Rmm.java:319)\n  at ai.rapids.cudf.Rmm.alloc(Rmm.java:308)\n  at ai.rapids.cudf.DeviceMemoryBuffer.allocate(DeviceMemoryBuffer.java:125)\n  at ai.rapids.cudf.JCudfSerialization.readTableFrom(JCudfSerialization.java:1477)\n  at ai.rapids.cudf.JCudfSerialization.readTableFrom(JCudfSerialization.java:1522)\n  at com.nvidia.spark.rapids.GpuColumnarBatchSerializerInstance$$anon$2$$anon$3.tryReadNext(GpuColumnarBatchSerializer.scala:152)\n  at com.nvidia.spark.rapids.GpuColumnarBatchSerializerInstance$$anon$2$$anon$3.hasNext(GpuColumnarBatchSerializer.scala:175)\n  at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:488)\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n  at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n  at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n  at com.nvidia.spark.rapids.RemoveEmptyBatchIterator.hasNext(GpuCoalesceBatches.scala:125)\n  at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.next(GpuCoalesceBatches.scala:281)\n  at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.next(GpuCoalesceBatches.scala:148)\n  at com.nvidia.spark.rapids.GpuColumnarBatchSorter$$anon$1.loadNextBatch(GpuSortExec.scala:141)\n  at com.nvidia.spark.rapids.GpuColumnarBatchSorter$$anon$1.hasNext(GpuSortExec.scala:188)\n  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.gpucolumnartorow_nextBatch_0$(Unknown Source)\n  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n  at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n  at org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n  at org.apache.spark.sql.execution.joins.SortMergeFullOuterJoinScanner.advancedLeft(SortMergeJoinExec.scala:1042)\n  at org.apache.spark.sql.execution.joins.SortMergeFullOuterJoinScanner.\u003cinit\u003e(SortMergeJoinExec.scala:1032)\n  at org.apache.spark.sql.execution.joins.SortMergeJoinExec.$anonfun$doExecute$1(SortMergeJoinExec.scala:286)\n  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n  at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n  at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n  at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n  at org.apache.spark.scheduler.Task.run(Task.scala:127)\n  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n  ... 3 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d2"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d3"
            },
            {
              "jobUrl": "http://PC192.168.2.5.station:4040/jobs/job?id\u003d4"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606328166907_1759603769",
      "id": "paragraph_1606328166907_1759603769",
      "dateCreated": "2020-11-25 20:16:06.907",
      "dateStarted": "2020-11-25 23:58:59.748",
      "dateFinished": "2020-11-26 00:29:43.883",
      "status": "ERROR"
    },
    {
      "title": "Explode Affiliations \u0026 add seqNum ",
      "text": "%spark\n\nimport org.apache.spark.sql.functions.countDistinct;\nimport org.apache.spark.storage.StorageLevel;\n\nval MAG_HOME \u003d \"/media/datadisk/Datasets/MAG/20201109/mag\"\nval paperAuthorsAffTsvFilename \u003d \"PaperAuthorAffiliations.txt\"\n\n\nval paperAuthorAffSchema \u003d new StructType().\n                add(\"paperId\", LongType, false).\n                add(\"authorId\", LongType, false).                \n                add(\"affiliationId\", LongType, true).\n                add(\"authorSequenceNumber\",IntegerType, true).\n                add(\"originalAuthor\", StringType, true).\n                add(\"originalAffiliation\", StringType, true)\n\n                \nval paperAuthorAffdf \u003d spark.read.options(Map(\"sep\"-\u003e\"\\t\", \"header\"-\u003e \"false\")).\n                schema(paperAuthorAffSchema).\n                csv(s\"file://$MAG_HOME/$paperAuthorsAffTsvFilename\")\n                .persist(StorageLevel.DISK_ONLY)\n\n\nprintln(\"paperAuthorAffdf cnt:\" + paperAuthorAffdf.count())\nval paperIdsdf \u003d paperAuthorAffdf.select(countDistinct(\"paperId\"))\npaperIdsdf.show(false)\nval authorIdsdf \u003d paperAuthorAffdf.select(countDistinct(\"authorId\")) \nauthorIdsdf.show(false)\n\n\n\nval S2_MAG_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\")\n\nprintln(\"paperAuthorAffdf cnt:\" + S2_MAG_df.count())\nval paperIdsdf2 \u003d S2_MAG_df.select(countDistinct(\"MAGpaperId\")) \npaperIdsdf2.show(false)\nval authorIdsdf2 \u003d S2_MAG_df.select(countDistinct(\"MAGauthorId\")) \nauthorIdsdf2.show(false)\n\n\n\nval PKGinitdf \u003d paperAuthorAffdf\n                   .join(S2_MAG_df, paperAuthorAffdf(\"paperId\") \u003d\u003d\u003d S2_MAG_df(\"MAGpaperId\")  \u0026\u0026  paperAuthorAffdf(\"authorId\")\u003d\u003d\u003dS2_MAG_df(\"MAGauthorId\") , \"inner\")                  \n                   .select(S2_MAG_df(\"MAGpaperId\"),   S2_MAG_df(\"MAGauthorId\"), paperAuthorAffdf(\"affiliationId\"), paperAuthorAffdf(\"authorSequenceNumber\"), \n                          S2_MAG_df(\"S2authorId\"),S2_MAG_df(\"S2paperId\"))\n                          \nPKGinitdf.write.parquet(\"/media/datadisk/Datasets/MAG_S2/PKGinitdf.parquet\")                    ",
      "user": "anonymous",
      "dateUpdated": "2020-11-22 23:26:32.618",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "paperAuthorAffdf cnt:664059589\n+-----------------------+\n|count(DISTINCT paperId)|\n+-----------------------+\n|244449978              |\n+-----------------------+\n\n+------------------------+\n|count(DISTINCT authorId)|\n+------------------------+\n|259658718               |\n+------------------------+\n\npaperAuthorAffdf cnt:714744779\n+--------------------------+\n|count(DISTINCT MAGpaperId)|\n+--------------------------+\n|243110801                 |\n+--------------------------+\n\n+---------------------------+\n|count(DISTINCT MAGauthorId)|\n+---------------------------+\n|258127231                  |\n+---------------------------+\n\nimport org.apache.spark.sql.functions.countDistinct\nimport org.apache.spark.storage.StorageLevel\n\u001b[1m\u001b[34mMAG_HOME\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d /media/datadisk/Datasets/MAG/20201109/mag\n\u001b[1m\u001b[34mpaperAuthorsAffTsvFilename\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d PaperAuthorAffiliations.txt\n\u001b[1m\u001b[34mpaperAuthorAffSchema\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.types.StructType\u001b[0m \u003d StructType(StructField(paperId,LongType,false), StructField(authorId,LongType,false), StructField(affiliationId,LongType,true), StructField(authorSequenceNumber,IntegerType,true), StructField(originalAuthor,StringType,true), StructField(originalAffiliation,StringType,true))\n\u001b[1m\u001b[34mpaperAuthorAffdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [paperId: bigint, authorId: bigint ... 4 more fields]\n\u001b[1m...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d12"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d13"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d14"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d15"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d16"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d17"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d18"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d19"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606036250517_213251448",
      "id": "paragraph_1606036250517_213251448",
      "dateCreated": "2020-11-22 11:10:50.517",
      "dateStarted": "2020-11-22 16:04:25.022",
      "dateFinished": "2020-11-22 17:25:06.696",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nimport org.apache.spark.storage.StorageLevel;\nimport org.apache.spark.sql.functions.countDistinct;\nimport  org.apache.spark.sql.functions._\nimport org.apache.commons.lang3.StringUtils;\nimport java.util.Calendar;\n\n\n\nval S2_MAG_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet\")\nprintln(\"S2_MAG_df cnt:\"+S2_MAG_df.count())\n\nval S2_MAG_df_diffs \u003d S2_MAG_df.filter($\"S2doi\"\u003d!\u003d\"\"  \u0026\u0026 $\"S2doi\".isNotNull \u0026\u0026 $\"S2doi\"\u003d!\u003d$\"MAGdoi\")\n    .cache()\n\nprintln(\"s2doi diffs cnt:\"+S2_MAG_df_diffs.count())\nprintln(Calendar.getInstance().getTime())\n\n/*\nprintln(Calendar.getInstance().getTime())\nS2_MAG_df.groupBy($\"MAGdoi\")\n.agg( collect_list($\"MAGshortNormName\") as \"magauthors\", collect_list($\"S2shortNormName\") as \"s2authors\").show(10)\n\nprintln(Calendar.getInstance().getTime())\n*/\n\n//val dfdoidiffs \u003d S2_MAG_df.select(countDistinct(\"S2doi\"))\n//dfdoidiffs.show(false)\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-01 11:30:11.879",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.spark.sql.AnalysisException: Path does not exist: file:/media/datadisk/Datasets/MAG_S2/S2_MAG_df.parquet;\n  at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:764)\n  at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)\n  at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)\n  at scala.collection.immutable.List.flatMap(List.scala:355)\n  at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:751)\n  at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:580)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:405)\n  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\n  at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\n  at scala.Option.getOrElse(Option.scala:189)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\n  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:755)\n  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:733)\n  ... 49 elided\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606292346869_653532528",
      "id": "paragraph_1606292346869_653532528",
      "dateCreated": "2020-11-25 10:19:06.869",
      "dateStarted": "2020-12-01 11:30:11.882",
      "dateFinished": "2020-12-01 11:30:12.172",
      "status": "ERROR"
    },
    {
      "title": "Statistics ",
      "text": "%spark\n\nval orcid_df \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/orcid.parquet\")\n.cache()\n\nprintln(\"paperAuthorAffdf cnt:\" + orcid_df.count())\nval paperIdsdf4 \u003d orcid_df.select(countDistinct(\"doi\")) \npaperIdsdf4.show(false)\nval authorIdsdf4 \u003d orcid_df.select(countDistinct(\"orcId\")) \nauthorIdsdf4.show(false)\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-24 11:13:27.069",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "paperAuthorAffdf cnt:34108075\n+-------------------+\n|count(DISTINCT doi)|\n+-------------------+\n|20145324           |\n+-------------------+\n\n+---------------------+\n|count(DISTINCT orcId)|\n+---------------------+\n|2110177              |\n+---------------------+\n\n\u001b[1m\u001b[34morcid_df\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [doi: string, ORCfullName: string ... 4 more fields]\n\u001b[1m\u001b[34mpaperIdsdf4\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [count(DISTINCT doi): bigint]\n\u001b[1m\u001b[34mauthorIdsdf4\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [count(DISTINCT orcId): bigint]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d2"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d3"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606138331418_98467935",
      "id": "paragraph_1606138331418_98467935",
      "dateCreated": "2020-11-23 15:32:11.418",
      "dateStarted": "2020-11-23 20:35:07.694",
      "dateFinished": "2020-11-23 20:35:45.582",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-24 11:12:50.591",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606209170591_423055544",
      "id": "paragraph_1606209170591_423055544",
      "dateCreated": "2020-11-24 11:12:50.591",
      "status": "READY"
    },
    {
      "text": "%spark\nval PKGinitdf \u003d spark.read.parquet(\"/media/datadisk/Datasets/MAG_S2/PKGinitdf.parquet\")\n.persist(StorageLevel.DISK_ONLY)\n\nprintln(\"paperAuthorAffdf cnt:\" + PKGinitdf.count())\nval paperIdsdf3 \u003d PKGinitdf.select(countDistinct(\"MAGpaperId\")) \npaperIdsdf3.show(false)\nval authorIdsdf3 \u003d PKGinitdf.select(countDistinct(\"MAGauthorId\")) \nauthorIdsdf3.show(false)\n\nPKGinitdf.show(20)\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-22 18:04:36.521",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "paperAuthorAffdf cnt:661888441\n+--------------------------+\n|count(DISTINCT MAGpaperId)|\n+--------------------------+\n|243110801                 |\n+--------------------------+\n\n+---------------------------+\n|count(DISTINCT MAGauthorId)|\n+---------------------------+\n|258127231                  |\n+---------------------------+\n\n+----------+-----------+-------------+--------------------+----------+--------------------+\n|MAGpaperId|MAGauthorId|affiliationId|authorSequenceNumber|S2authorId|           S2paperId|\n+----------+-----------+-------------+--------------------+----------+--------------------+\n|   2256735| 2123292459|         null|                   3|  34500706|893ab65873acf4ea7...|\n|   2256427| 2657408789|         null|                   1|  94839152|e5725d36113794257...|\n|   2255007| 2046440042|         null|                   1|      null|                null|\n|   5365974| 1159491402|         null|                   3|  96168803|f21e376cbaf2bdfdb...|\n|   5364942| 2692433392|         null|                   1|  13058996|9ddf923283c05282c...|\n|   5368942| 2147127826|   1280527723|                   2|      null|                null|\n|   5363227| 2656047705|         null|                   1| 102370015|a9090f1a03c7707c7...|\n|   8575627| 2718021196|         null|                   1| 115737526|32b3252af3bbd638d...|\n|   8578446| 2719212326|         null|                   4|  48371938|e35a64609ac2059f3...|\n|   8575304| 2154328982|         null|                   2| 145026931|fd2442f7393cf649c...|\n|  14903071| 2156178794|         null|                   1| 144260253|fc793f1f50e15ea05...|\n|  14904768| 1986927034|         null|                   1|  50318863|e3b87a165383301c8...|\n|  14902604| 2724545588|         null|                   1| 135257711|976ae90b592de944c...|\n|  14900795| 2213038480|         null|                   5|   2886859|f43ba2e189435c5a8...|\n|  14900885| 2137219327|    165690674|                   1|   5334859|15222f98edca709f0...|\n|  14905300| 1989737588|         null|                   3|  46539538|cf6ccf85cc8ff732d...|\n|  14901123| 2481459642|         null|                   1|      null|                null|\n|  14901123| 2629246837|         null|                   2|      null|                null|\n|  18032892| 2304025315|         null|                   2|  15602239|ca6c45e7cc7ce6083...|\n|  18034051| 2036233860|         null|                   1| 119120210|29ada1014056b7e02...|\n+----------+-----------+-------------+--------------------+----------+--------------------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mPKGinitdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [MAGpaperId: bigint, MAGauthorId: bigint ... 4 more fields]\n\u001b[1m\u001b[34mpaperIdsdf3\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [count(DISTINCT MAGpaperId): bigint]\n\u001b[1m\u001b[34mauthorIdsdf3\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [count(DISTINCT MAGauthorId): bigint]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d20"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d21"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d22"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d23"
            },
            {
              "jobUrl": "http://192.168.2.5:4040/jobs/job?id\u003d24"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1606060994366_122591239",
      "id": "paragraph_1606060994366_122591239",
      "dateCreated": "2020-11-22 18:03:14.366",
      "dateStarted": "2020-11-22 18:04:36.524",
      "dateFinished": "2020-11-22 18:13:26.424",
      "status": "FINISHED"
    }
  ],
  "name": "Match_S2_MAG_ORCiD",
  "id": "2FQRWCV2A",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview2",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}